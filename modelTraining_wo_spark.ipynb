{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data_path = '/Users/mohammad.enayet/Documents/Personal/Duke-Dataset/Clinical_and_Other_Features_final_final.xlsx'\n",
    "features_path = '/Users/mohammad.enayet/Documents/Personal/Duke-Dataset/features_extracted_VGG16.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = pd.read_excel(clinical_data_path)\n",
    "\n",
    "# Rename columns for consistency\n",
    "clinical_data.columns = [col.replace(' ', '_') for col in clinical_data.columns]\n",
    "clinical_data = clinical_data.rename(columns={'Patient_ID': 'patient_id', 'Pathologic_Response_to_Neoadjuvant_Therapy': 'response'})\n",
    "\n",
    "# Convert 'Breast_MRI_001' to '001' in the patient_id column\n",
    "clinical_data['patient_id'] = clinical_data['patient_id'].apply(lambda x: x.split('_')[-1] if isinstance(x, str) else x)\n",
    "\n",
    "# Convert response to binary: 1 or 2 means response, anything other than 1 or 2 means no response\n",
    "clinical_data['response'] = clinical_data['response'].apply(lambda x: 1 if x in [1, 2] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Date_of_Birth_(Days)</th>\n",
       "      <th>Menopause_(at_diagnosis)</th>\n",
       "      <th>Race_and_Ethnicity</th>\n",
       "      <th>ER</th>\n",
       "      <th>PR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>Mol_Subtype</th>\n",
       "      <th>Staging(Nodes)</th>\n",
       "      <th>Staging</th>\n",
       "      <th>Multicentric/Multifocal</th>\n",
       "      <th>Contralateral_Breast_Involvement</th>\n",
       "      <th>Lymphadenopathy_or_Suspicious_Nodes</th>\n",
       "      <th>Skin/Nipple_Invovlement</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>-15209</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>-14061</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005</td>\n",
       "      <td>-13932</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009</td>\n",
       "      <td>-20541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010</td>\n",
       "      <td>-24712</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>285</td>\n",
       "      <td>-17088</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>287</td>\n",
       "      <td>-16980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>290</td>\n",
       "      <td>-14768</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>293</td>\n",
       "      <td>-18324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>298</td>\n",
       "      <td>-15338</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  Date_of_Birth_(Days)  Menopause_(at_diagnosis)  \\\n",
       "0          001                -15209                         0   \n",
       "1          002                -14061                         0   \n",
       "2          005                -13932                         0   \n",
       "3          009                -20541                         1   \n",
       "4          010                -24712                         1   \n",
       "..         ...                   ...                       ...   \n",
       "100        285                -17088                         0   \n",
       "101        287                -16980                         0   \n",
       "102        290                -14768                         0   \n",
       "103        293                -18324                         0   \n",
       "104        298                -15338                         0   \n",
       "\n",
       "     Race_and_Ethnicity  ER  PR  HER2  Mol_Subtype  Staging(Nodes)  Staging  \\\n",
       "0                     2   0   0     1            2               1        0   \n",
       "1                     2   0   0     0            3               0        0   \n",
       "2                     5   1   0     1            1               1        0   \n",
       "3                     1   0   0     0            3               0        0   \n",
       "4                     1   0   0     0            3               2        0   \n",
       "..                  ...  ..  ..   ...          ...             ...      ...   \n",
       "100                   2   1   1     0            0               1        0   \n",
       "101                   1   1   1     0            0               1        0   \n",
       "102                   1   1   1     0            0               1        0   \n",
       "103                   1   0   0     0            3               1       -1   \n",
       "104                   2   1   0     0            0               1        0   \n",
       "\n",
       "     Multicentric/Multifocal  Contralateral_Breast_Involvement  \\\n",
       "0                          0                                 0   \n",
       "1                          0                                 0   \n",
       "2                          1                                 0   \n",
       "3                          1                                 0   \n",
       "4                          1                                 0   \n",
       "..                       ...                               ...   \n",
       "100                        1                                 0   \n",
       "101                        1                                 0   \n",
       "102                        1                                 1   \n",
       "103                        1                                 0   \n",
       "104                        1                                 0   \n",
       "\n",
       "     Lymphadenopathy_or_Suspicious_Nodes  Skin/Nipple_Invovlement  response  \n",
       "0                                      0                        0         0  \n",
       "1                                      0                        0         1  \n",
       "2                                      1                        0         1  \n",
       "3                                      0                        0         1  \n",
       "4                                      1                        0         0  \n",
       "..                                   ...                      ...       ...  \n",
       "100                                    0                        0         1  \n",
       "101                                    0                        0         0  \n",
       "102                                    1                        0         0  \n",
       "103                                    0                        1         0  \n",
       "104                                    1                        0         0  \n",
       "\n",
       "[105 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features from the compressed file\n",
    "\n",
    "with gzip.open(features_path, 'rb') as f:\n",
    "    features_without_pyspark = pickle.load(f)\n",
    "\n",
    "# Extract patient IDs from the keys\n",
    "features_data = {\n",
    "    'patient_id': [key.split('-')[0] for key in features_without_pyspark.keys()],\n",
    "    **{f'feature_{i}': [features_without_pyspark[key][i] for key in features_without_pyspark.keys()] \n",
    "       for i in range(len(next(iter(features_without_pyspark.values()))))}\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the features\n",
    "features_df = pd.DataFrame(features_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_25078</th>\n",
       "      <th>feature_25079</th>\n",
       "      <th>feature_25080</th>\n",
       "      <th>feature_25081</th>\n",
       "      <th>feature_25082</th>\n",
       "      <th>feature_25083</th>\n",
       "      <th>feature_25084</th>\n",
       "      <th>feature_25085</th>\n",
       "      <th>feature_25086</th>\n",
       "      <th>feature_25087</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.039151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.669905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.982861</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.478312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.031435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.292235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6522</td>\n",
       "      <td>...</td>\n",
       "      <td>29.501215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.871337</td>\n",
       "      <td>2.640998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8788</th>\n",
       "      <td>577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.883359</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.369884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.450093</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.127481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8791</th>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.256354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811845</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.802909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766912</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8793 rows × 25089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0           717        0.0        0.0        0.0        0.0        0.0   \n",
       "1           132        0.0        0.0        0.0        0.0        0.0   \n",
       "2           285        0.0        0.0        0.0        0.0        0.0   \n",
       "3           258        0.0        0.0        0.0        0.0        0.0   \n",
       "4           850        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "8788        577        0.0        0.0        0.0        0.0        0.0   \n",
       "8789        041        0.0        0.0        0.0        0.0        0.0   \n",
       "8790        717        0.0        0.0        0.0        0.0        0.0   \n",
       "8791        198        0.0        0.0        0.0        0.0        0.0   \n",
       "8792        792        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      feature_5  feature_6  feature_7  feature_8  ...  feature_25078  \\\n",
       "0           0.0   0.000000        0.0     0.0000  ...       0.000000   \n",
       "1           0.0   0.000000        0.0     0.0000  ...       7.669905   \n",
       "2           0.0   4.478312        0.0     0.0000  ...      16.031435   \n",
       "3           0.0   0.000000        0.0     3.6522  ...      29.501215   \n",
       "4           0.0   0.000000        0.0     0.0000  ...      14.871337   \n",
       "...         ...        ...        ...        ...  ...            ...   \n",
       "8788        0.0   0.000000        0.0     0.0000  ...       0.000000   \n",
       "8789        0.0   0.000000        0.0     0.0000  ...       9.369884   \n",
       "8790        0.0   0.000000        0.0     0.0000  ...       0.000000   \n",
       "8791        0.0   0.000000        0.0     0.0000  ...       6.256354   \n",
       "8792        0.0   0.000000        0.0     0.0000  ...       8.802909   \n",
       "\n",
       "      feature_25079  feature_25080  feature_25081  feature_25082  \\\n",
       "0          0.000000            0.0            0.0            0.0   \n",
       "1          0.000000            0.0            0.0            0.0   \n",
       "2          0.000000            0.0            0.0            0.0   \n",
       "3          0.000000            0.0            0.0            0.0   \n",
       "4          2.640998            0.0            0.0            0.0   \n",
       "...             ...            ...            ...            ...   \n",
       "8788       0.000000            0.0            0.0            0.0   \n",
       "8789       0.000000            0.0            0.0            0.0   \n",
       "8790       0.000000            0.0            0.0            0.0   \n",
       "8791       0.000000            0.0            0.0            0.0   \n",
       "8792       0.000000            0.0            0.0            0.0   \n",
       "\n",
       "      feature_25083  feature_25084  feature_25085  feature_25086  \\\n",
       "0               0.0            0.0            0.0       8.039151   \n",
       "1               0.0            0.0            0.0      10.982861   \n",
       "2               0.0            0.0            0.0       4.292235   \n",
       "3               0.0            0.0            0.0       0.992551   \n",
       "4               0.0            0.0            0.0       0.000000   \n",
       "...             ...            ...            ...            ...   \n",
       "8788            0.0            0.0            0.0       3.883359   \n",
       "8789            0.0            0.0            0.0       2.450093   \n",
       "8790            0.0            0.0            0.0      10.127481   \n",
       "8791            0.0            0.0            0.0       0.811845   \n",
       "8792            0.0            0.0            0.0       0.766912   \n",
       "\n",
       "      feature_25087  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "8788            0.0  \n",
       "8789            0.0  \n",
       "8790            0.0  \n",
       "8791            0.0  \n",
       "8792            0.0  \n",
       "\n",
       "[8793 rows x 25089 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auroc(y_true, y_scores, model_name):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "\n",
    "def plot_loss_curves(train_losses, val_losses, test_losses, model_name):\n",
    "    iterations = range(1, len(train_losses) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(iterations, train_losses, label='Training Loss')\n",
    "    plt.plot(iterations, val_losses, label='Validation Loss')\n",
    "    plt.plot(iterations, test_losses, label='Test Loss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{model_name} Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='accuracy')\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model_with_cross_val(model, X, y, cv=5):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "    print(f'Cross-validation scores: {scores}')\n",
    "    print(f'Mean cross-validation score: {np.mean(scores)}')\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(len(feature_names)), importances[indices], color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(len(feature_names)), feature_names, rotation=90)\n",
    "    plt.xlim([-1, len(feature_names)])\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(model, param_grid,X_pca,y, X_train, y_train, X_val, y_val, X_test, y_test, model_name):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    best_model = grid_result.best_estimator_\n",
    "    \n",
    "    # Validation Performance\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Test Performance\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    auroc = roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    print(f\"{model_name} validation accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"{model_name} test accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"{model_name} precision: {precision:.4f}\")\n",
    "    print(f\"{model_name} recall: {recall:.4f}\")\n",
    "    print(f\"{model_name} F1 score: {f1:.4f}\")\n",
    "    print(f\"{model_name} AUROC: {auroc:.4f}\")\n",
    "    print(f\"{model_name} training time: {training_time:.4f} seconds\")\n",
    "    print(f\"Best parameters for {model_name}: {grid_result.best_params_}\")\n",
    "    \n",
    "    #plot_auroc(y_test, y_test_proba, model_name)\n",
    "    #plot_confusion_matrix(y_test, y_test_pred, model_name)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    #plot_learning_curve(best_model, f\"Learning Curves ({model_name})\", X_pca, y, cv=5)\n",
    "    \n",
    "    # Cross-validation evaluation\n",
    "    evaluate_model_with_cross_val(best_model, X_pca, y, cv=5)\n",
    "    \n",
    "    # Plot feature importance for ensemble models\n",
    "    #if hasattr(best_model, 'feature_importances_'):\n",
    "    #    plot_feature_importance(best_model, [f'pca_{i}' for i in range(X_pca.shape[1])])\n",
    "    \n",
    "    # Plot loss curves if the model supports it\n",
    "    #if hasattr(best_model, 'staged_predict_proba'):\n",
    "    #    train_losses = []\n",
    "    #    val_losses = []\n",
    "    #    test_losses = []\n",
    "    #    for train_pred_proba, val_pred_proba, test_pred_proba in zip(best_model.staged_predict_proba(X_train),\n",
    "    #                                                                 best_model.staged_predict_proba(X_val),\n",
    "    #                                                                 best_model.staged_predict_proba(X_test)):\n",
    "    #        train_loss = np.mean((y_train - train_pred_proba[:, 1]) ** 2)\n",
    "    #        val_loss = np.mean((y_val - val_pred_proba[:, 1]) ** 2)\n",
    "    #        test_loss = np.mean((y_test - test_pred_proba[:, 1]) ** 2)\n",
    "    #        train_losses.append(train_loss)\n",
    "    #        val_losses.append(val_loss)\n",
    "    #        test_losses.append(test_loss)\n",
    "    #    plot_loss_curves(train_losses, val_losses, test_losses, model_name)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (3536, 25103)\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'patient_id' columns are of the same type\n",
    "features_df['patient_id'] = features_df['patient_id'].astype(str)\n",
    "clinical_data['patient_id'] = clinical_data['patient_id'].astype(str)\n",
    "\n",
    "# Combine extracted features with clinical data\n",
    "combined_df = features_df.merge(clinical_data, on='patient_id', how='left')\n",
    "\n",
    "# Check the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Check the shape of the combined DataFrame\n",
    "print(f\"Combined DataFrame shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assuming combined_df is your DataFrame\n",
    "## Separate features and target\n",
    "\n",
    "X = combined_df.drop(columns=['patient_id', 'response'])\n",
    "y = combined_df['response']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=35)  # Adjust the number of components as needed\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_pca, y, test_size=0.5, random_state=22)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression validation accuracy: 0.8066\n",
      "Logistic Regression test accuracy: 0.7986\n",
      "Logistic Regression precision: 0.7538\n",
      "Logistic Regression recall: 0.6378\n",
      "Logistic Regression F1 score: 0.6910\n",
      "Logistic Regression AUROC: 0.8800\n",
      "Logistic Regression training time: 4.1804 seconds\n",
      "Best parameters for Logistic Regression: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Cross-validation scores: [0.77683616 0.78925035 0.7864215  0.77934936 0.79490806]\n",
      "Mean cross-validation score: 0.7853530873668481\n",
      "Random Forest validation accuracy: 0.9966\n",
      "Random Forest test accuracy: 0.9989\n",
      "Random Forest precision: 1.0000\n",
      "Random Forest recall: 0.9968\n",
      "Random Forest F1 score: 0.9984\n",
      "Random Forest AUROC: 1.0000\n",
      "Random Forest training time: 12.8921 seconds\n",
      "Best parameters for Random Forest: {'max_depth': 15, 'n_estimators': 200}\n",
      "Cross-validation scores: [0.97740113 0.99858557 0.99717115 0.99292786 0.99434229]\n",
      "Mean cross-validation score: 0.9920856008118971\n",
      "Gradient Boosted Trees validation accuracy: 0.9943\n",
      "Gradient Boosted Trees test accuracy: 0.9977\n",
      "Gradient Boosted Trees precision: 0.9968\n",
      "Gradient Boosted Trees recall: 0.9968\n",
      "Gradient Boosted Trees F1 score: 0.9968\n",
      "Gradient Boosted Trees AUROC: 1.0000\n",
      "Gradient Boosted Trees training time: 130.7810 seconds\n",
      "Best parameters for Gradient Boosted Trees: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 150}\n",
      "Cross-validation scores: [0.98305085 0.99292786 0.99717115 0.98868458 0.99717115]\n",
      "Mean cross-validation score: 0.9918011171577206\n",
      "XGBoost validation accuracy: 0.9943\n",
      "XGBoost test accuracy: 0.9977\n",
      "XGBoost precision: 0.9968\n",
      "XGBoost recall: 0.9968\n",
      "XGBoost F1 score: 0.9968\n",
      "XGBoost AUROC: 1.0000\n",
      "XGBoost training time: 19.5535 seconds\n",
      "Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Cross-validation scores: [0.96892655 0.99717115 0.99292786 0.99292786 0.99151344]\n",
      "Mean cross-validation score: 0.9886933729692581\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "train_and_evaluate(lr, param_grid_lr,X_pca,y, X_train, y_train, X_val, y_val, X_test, y_test, \"Logistic Regression\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'max_depth': [5, 10, 15, 20, 30]\n",
    "}\n",
    "train_and_evaluate(rf, param_grid_rf,X_pca,y, X_train, y_train, X_val, y_val, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "# Gradient Boosted Trees\n",
    "gbt = GradientBoostingClassifier()\n",
    "param_grid_gbt = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "train_and_evaluate(gbt, param_grid_gbt,X_pca,y, X_train, y_train, X_val, y_val, X_test, y_test, \"Gradient Boosted Trees\")\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(probability=True)\n",
    "param_grid_svm = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "#train_and_evaluate(svm, param_grid_svm, X_train, y_train, X_val, y_val, X_test, y_test, \"Support Vector Machine\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.5],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "train_and_evaluate(xgb_model, param_grid_xgb,X_pca,y, X_train, y_train, X_val, y_val, X_test, y_test, \"XGBoost\")\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "#train_and_evaluate(lgb_model, param_grid_lgb, X_train, y_train, X_val, y_val, X_test, y_test, \"LightGBM\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
