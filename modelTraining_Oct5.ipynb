{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Sklearn and Imbalanced-learn Libraries\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, balanced_accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils import resample\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Additional Libraries\n",
    "from sklearn.base import clone\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries with GPU Support\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# For SHAP values\n",
    "import shap\n",
    "\n",
    "# Statistical Tests\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# For progress monitoring\n",
    "from tqdm import tqdm\n",
    "from kneed import KneeLocator\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings to reduce clutter\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Necessary imports\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "clinical_data_path = '/Users/mohammad.enayet/Documents/Personal/Research/sparkMLproject/Clinical_and_Other_Features_final_comb.xlsx'\n",
    "features_path = '/Users/mohammad.enayet/Documents/Personal/Research/sparkMLproject/features_extracted_VGG16.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function: Load and Process Data\n",
    "def load_clinical_data(clinical_data_path):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses clinical data from an Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - clinical_data_path (str): Path to the clinical data Excel file.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Preprocessed clinical data.\n",
    "    \"\"\"\n",
    "    print(\"Loading clinical data...\")\n",
    "    clinical_data = pd.read_excel(clinical_data_path)\n",
    "\n",
    "    # Rename columns for consistency\n",
    "    clinical_data.columns = [col.replace(' ', '_') for col in clinical_data.columns]\n",
    "    clinical_data = clinical_data.rename(\n",
    "        columns={\n",
    "            'Patient_ID': 'patient_id',\n",
    "            'Pathologic_Response_to_Neoadjuvant_Therapy': 'response'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert 'Breast_MRI_001' to '001' in the patient_id column\n",
    "    clinical_data['patient_id'] = clinical_data['patient_id'].apply(\n",
    "        lambda x: x.split('_')[-1] if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "    # Convert response to binary: 1 means pCR, else non-pCR\n",
    "    clinical_data['response'] = clinical_data['response'].apply(\n",
    "        lambda x: 1 if x == 1 else 0\n",
    "    )\n",
    "\n",
    "    # Preprocess clinical data\n",
    "    clinical_data['patient_id'] = clinical_data['patient_id'].astype(str)\n",
    "\n",
    "    # Separate numerical and categorical columns\n",
    "    patient_id_cols = [\"patient_id\"]\n",
    "    response_cols = [\"response\"]\n",
    "    numerical_cols = [\"Date_of_Birth\"]  # Consider converting to 'Age at Diagnosis'\n",
    "    categorical_cols = clinical_data.columns[\n",
    "        (clinical_data.columns != \"Date_of_Birth\") &\n",
    "        (clinical_data.columns != \"patient_id\") &\n",
    "        (clinical_data.columns != \"response\")\n",
    "    ]\n",
    "\n",
    "    numerical_df = clinical_data[numerical_cols]\n",
    "    patient_id_df = clinical_data[patient_id_cols]\n",
    "    response_df = clinical_data[response_cols]\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    clinical_data[categorical_cols] = clinical_data[categorical_cols].astype('category')\n",
    "    categorical_df = pd.get_dummies(clinical_data[categorical_cols], drop_first=True)\n",
    "    categorical_df = categorical_df.astype(int)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    encoded_df = pd.concat(\n",
    "        [patient_id_df, numerical_df, categorical_df, response_df],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    print(\"Clinical data loaded and processed.\")\n",
    "    return encoded_df\n",
    "\n",
    "def load_image_features(features_path):\n",
    "    \"\"\"\n",
    "    Loads and processes image features from a compressed pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - features_path (str): Path to the compressed pickle file containing image features.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed image features.\n",
    "    \"\"\"\n",
    "    print(\"Loading image features...\")\n",
    "    with gzip.open(features_path, 'rb') as f:\n",
    "        features_dict = pickle.load(f)\n",
    "\n",
    "    # Extract patient IDs and features\n",
    "    features_data = {\n",
    "        'patient_id': [key.split('-')[0] for key in features_dict.keys()],\n",
    "        **{\n",
    "            f'feature_{i}': [features_dict[key][i] for key in features_dict.keys()]\n",
    "            for i in range(len(next(iter(features_dict.values()))))\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame\n",
    "    features_df = pd.DataFrame(features_data)\n",
    "    features_df['patient_id'] = features_df['patient_id'].astype(str)\n",
    "    print(\"Image features loaded.\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(clinical_data_path, features_path):\n",
    "    clinical_data_processed = load_clinical_data(clinical_data_path)\n",
    "    features_df = load_image_features(features_path)\n",
    "    clinical_data_processed['patient_id'] = clinical_data_processed['patient_id'].astype(str)\n",
    "    features_df['patient_id'] = features_df['patient_id'].astype(str)\n",
    "\n",
    "    # Prepare three variations of the dataset\n",
    "    print(\"Preparing dataset variations...\")\n",
    "\n",
    "    datasets = {}\n",
    "\n",
    "    # Handle missing data in image features\n",
    "    print(\"Imputing missing values in image features...\")\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    features_df_imputed = imputer.fit_transform(features_df.drop(columns=['patient_id']))\n",
    "\n",
    "    # Feature scaling\n",
    "    print(\"Scaling image features...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    features_df_scaled = scaler.fit_transform(features_df_imputed)\n",
    "\n",
    "    # Create a DataFrame for scaled features\n",
    "    features_scaled_df = pd.DataFrame(features_df_scaled, columns=[f'feature_{i}' for i in range(features_df_scaled.shape[1])])\n",
    "    features_scaled_df['patient_id'] = features_df['patient_id'].values\n",
    "\n",
    "    # Now, merge scaled image features with clinical data\n",
    "    data_scaled = features_scaled_df.merge(\n",
    "        clinical_data_processed,\n",
    "        on='patient_id',\n",
    "        how='inner'\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # 1. Image Features (Scaled)\n",
    "    image_feature_columns = [col for col in data_scaled.columns if 'feature_' in col]\n",
    "\n",
    "    X_image = data_scaled[image_feature_columns]\n",
    "    y_image = data_scaled['response'].astype(int)\n",
    "    groups_image = data_scaled['patient_id']\n",
    "\n",
    "    # 2. Clinical Features\n",
    "    # Subset clinical data to include only patients present in data_scaled\n",
    "    patient_ids_in_data_scaled = clinical_data_processed['patient_id'].isin(data_scaled['patient_id'])\n",
    "    clinical_data_in_data_scaled = clinical_data_processed[patient_ids_in_data_scaled].reset_index(drop=True)\n",
    "\n",
    "    X_clinical = clinical_data_in_data_scaled.drop(columns=['patient_id', 'response'])\n",
    "    y_clinical = clinical_data_in_data_scaled['response'].astype(int)\n",
    "    groups_clinical = clinical_data_in_data_scaled['patient_id']\n",
    "\n",
    "    # 3. Combined Features (Scaled image features + clinical data)\n",
    "    # Exclude 'patient_id' and 'response' from features\n",
    "    exclude_columns = ['patient_id', 'response']\n",
    "    X_combined = data_scaled.drop(columns=exclude_columns)\n",
    "    y_combined = data_scaled['response'].astype(int)\n",
    "    groups_combined = data_scaled['patient_id']\n",
    "\n",
    "    # Preprocess each dataset variation\n",
    "    def preprocess_data(X):\n",
    "        # Remove features with zero variance\n",
    "        variance_threshold = VarianceThreshold(threshold=0)\n",
    "        X_var = variance_threshold.fit_transform(X)\n",
    "        feature_names = X.columns[variance_threshold.get_support(indices=True)]\n",
    "        X = pd.DataFrame(X_var, columns=feature_names)\n",
    "        return X\n",
    "\n",
    "    X_combined = preprocess_data(X_combined)\n",
    "    X_clinical = preprocess_data(X_clinical)\n",
    "    X_image = preprocess_data(X_image)\n",
    "\n",
    "    datasets['Combined'] = (X_combined, y_combined, groups_combined)\n",
    "    datasets['Clinical'] = (X_clinical, y_clinical, groups_clinical)\n",
    "    datasets['Image'] = (X_image, y_image, groups_image)\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clinical data...\n",
      "Clinical data loaded and processed.\n",
      "Loading image features...\n",
      "Image features loaded.\n",
      "Preparing dataset variations...\n",
      "Imputing missing values in image features...\n",
      "Scaling image features...\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "data_variations = load_and_preprocess_data(clinical_data_path, features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Combined Dataset\n",
      "Training set class distribution:\n",
      "response\n",
      "0    0.792833\n",
      "1    0.207167\n",
      "Name: proportion, dtype: float64\n",
      "Test set class distribution:\n",
      "response\n",
      "0    0.759479\n",
      "1    0.240521\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processing Clinical Dataset\n",
      "Training set class distribution:\n",
      "response\n",
      "0    0.770335\n",
      "1    0.229665\n",
      "Name: proportion, dtype: float64\n",
      "Test set class distribution:\n",
      "response\n",
      "0    0.773585\n",
      "1    0.226415\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processing Image Dataset\n",
      "Training set class distribution:\n",
      "response\n",
      "0    0.792833\n",
      "1    0.207167\n",
      "Name: proportion, dtype: float64\n",
      "Test set class distribution:\n",
      "response\n",
      "0    0.759479\n",
      "1    0.240521\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Data Train Test Split\n",
    "def stratified_group_split(X, y, groups, test_size=0.2, random_state=None):\n",
    "    # Create a DataFrame with groups and their corresponding class labels\n",
    "    group_df = pd.DataFrame({'group': groups, 'label': y})\n",
    "    group_df = group_df.drop_duplicates()\n",
    "\n",
    "    # Perform stratified split on groups\n",
    "    stratify = group_df['label']\n",
    "    group_train, group_test = train_test_split(\n",
    "        group_df['group'], test_size=test_size, random_state=random_state, stratify=stratify\n",
    "    )\n",
    "\n",
    "    # Select samples based on group splits\n",
    "    train_idx = X[groups.isin(group_train)].index\n",
    "    test_idx = X[groups.isin(group_test)].index\n",
    "\n",
    "    return train_idx, test_idx\n",
    "\n",
    "# Usage\n",
    "data_splits = {}\n",
    "\n",
    "for dataset_name, (X_full, y_full, groups) in data_variations.items():\n",
    "    print(f\"\\nProcessing {dataset_name} Dataset\")\n",
    "\n",
    "    # Ensure groups is a pandas Series with reset index\n",
    "    groups = pd.Series(groups).reset_index(drop=True)\n",
    "    y_full_series = pd.Series(y_full).reset_index(drop=True)\n",
    "    X_full = X_full.reset_index(drop=True)\n",
    "\n",
    "    train_idx, test_idx = stratified_group_split(X_full, y_full_series, groups, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_full = X_full.loc[train_idx].reset_index(drop=True)\n",
    "    y_train_full = y_full_series.loc[train_idx].reset_index(drop=True)\n",
    "    X_test_full = X_full.loc[test_idx].reset_index(drop=True)\n",
    "    y_test = y_full_series.loc[test_idx].reset_index(drop=True)\n",
    "\n",
    "    # Retrieve patient IDs for train and test sets\n",
    "    patient_ids_train = groups.loc[train_idx].reset_index(drop=True)\n",
    "    patient_ids_test = groups.loc[test_idx].reset_index(drop=True)\n",
    "\n",
    "    data_splits[dataset_name] = {\n",
    "        'X_train_full': X_train_full,\n",
    "        'X_test_full': X_test_full,\n",
    "        'y_train_full': y_train_full,\n",
    "        'y_test': y_test,\n",
    "        'patient_ids_train': patient_ids_train,\n",
    "        'patient_ids_test': patient_ids_test\n",
    "    }\n",
    "\n",
    "    # Verify class distribution\n",
    "    print(\"Training set class distribution:\")\n",
    "    print(y_train_full.value_counts(normalize=True))\n",
    "    print(\"Test set class distribution:\")\n",
    "    print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function: MannWhitney & RFECV Feature Selection\n",
    "class MannWhitneyUTestFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer for feature selection using the Mann-Whitney U test\n",
    "    with Bonferroni correction and optional parallelization.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.05, bonferroni=True, n_jobs=-1):\n",
    "        \"\"\"\n",
    "        Initialize the selector.\n",
    "\n",
    "        Parameters:\n",
    "        - alpha (float): The significance level for the Mann-Whitney U test.\n",
    "        - bonferroni (bool): Whether to apply Bonferroni correction.\n",
    "        - n_jobs (int): The number of jobs to run in parallel (default is -1, using all available cores).\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.bonferroni = bonferroni\n",
    "        self.n_jobs = n_jobs\n",
    "        self.selected_features_ = None\n",
    "\n",
    "    def _perform_test(self, col, X, y):\n",
    "        \"\"\"\n",
    "        Helper function to perform Mann-Whitney U test on a single feature.\n",
    "        \"\"\"\n",
    "        group0 = X.loc[y == 0, col]\n",
    "        group1 = X.loc[y == 1, col]\n",
    "        try:\n",
    "            _, p = mannwhitneyu(group0, group1, alternative='two-sided')\n",
    "        except ValueError:\n",
    "            p = 1  # Assign high p-value if test fails\n",
    "        return p\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the selector to the data by performing the Mann-Whitney U test for each feature.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (pd.DataFrame): The input feature matrix.\n",
    "        - y (pd.Series): The target variable.\n",
    "        \n",
    "        Returns:\n",
    "        - self: The fitted selector.\n",
    "        \"\"\"\n",
    "        # Ensure X is a DataFrame and y is a Series with matching indices\n",
    "        X = pd.DataFrame(X)\n",
    "        y = pd.Series(y, index=X.index)\n",
    "        \n",
    "        # Parallelized Mann-Whitney U tests\n",
    "        p_values = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._perform_test)(col, X, y) for col in X.columns\n",
    "        )\n",
    "        \n",
    "        self.p_values_ = np.array(p_values)\n",
    "        \n",
    "        # Apply Bonferroni correction if needed\n",
    "        if self.bonferroni:\n",
    "            corrected_alpha = self.alpha / X.shape[1]  # Adjust alpha by number of tests\n",
    "        else:\n",
    "            corrected_alpha = self.alpha\n",
    "\n",
    "        # Select features with p-values below the corrected alpha level\n",
    "        self.selected_features_ = X.columns[self.p_values_ < corrected_alpha]\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the data by selecting the features that passed the Mann-Whitney U test.\n",
    "\n",
    "        Parameters:\n",
    "        - X (pd.DataFrame): The input feature matrix.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: The selected feature matrix.\n",
    "        \"\"\"\n",
    "        # Ensure X is a DataFrame\n",
    "        X = pd.DataFrame(X)\n",
    "        return X.loc[:, self.selected_features_]\n",
    "    \n",
    "def manual_rfecv(X, y, estimator, cv, scoring='f1', min_features_to_select=5, step=0.1,  early_stopping_rounds=3):\n",
    "    \"\"\"\n",
    "    Manually performs Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "    using the specified estimator and cross-validation strategy.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Feature matrix.\n",
    "    - y (pd.Series): Target vector.\n",
    "    - estimator: The machine learning estimator to use for feature selection.\n",
    "    - cv: Cross-validation strategy.\n",
    "    - scoring (str): Scoring metric (default is 'f1').\n",
    "    - min_features_to_select (int): Minimum number of features to select.\n",
    "    - step (float): Proportion of features to remove at each iteration.\n",
    "    \n",
    "    Returns:\n",
    "    - best_features (list): The list of best selected features based on cross-validation score.\n",
    "    - history (pd.DataFrame): History of number of features and corresponding CV scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    step_num = int(max(1, step * n_features))  # Convert the step percentage to an absolute number of features\n",
    "    \n",
    "    # History to keep track of scores, feature sets and feature counts\n",
    "    history = []\n",
    "    feature_sets = []\n",
    "    \n",
    "    # Copy X to avoid modifying the original dataframe\n",
    "    X_remaining = X.copy()\n",
    "\n",
    "    # Early stopping tracking\n",
    "    no_improvement_rounds = 0\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    while X_remaining.shape[1] > min_features_to_select:\n",
    "        print(f\"Evaluating with {X_remaining.shape[1]} features...\")\n",
    "        n_features_remaining = X_remaining.shape[1]\n",
    "        step_num = int(max(1, step * n_features_remaining)) \n",
    "        \n",
    "        # Perform cross-validation with the current set of features\n",
    "        scores = cross_val_score(estimator, X_remaining, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        avg_score = np.mean(scores)\n",
    "        \n",
    "        # Append results to the history and store the current feature set\n",
    "        history.append((X_remaining.shape[1], round(avg_score, 2)))  # Round CV score to 3 decimal places\n",
    "        feature_sets.append(X_remaining.columns.tolist())\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            no_improvement_rounds = 0\n",
    "        else:\n",
    "            no_improvement_rounds += 1\n",
    "        \n",
    "        if no_improvement_rounds >= early_stopping_rounds:\n",
    "            print(\"Early stopping, no significant improvement.\")\n",
    "            break\n",
    "        \n",
    "        # Train the model and get feature importances\n",
    "        estimator.fit(X_remaining, y)\n",
    "        importances = estimator.feature_importances_\n",
    "        \n",
    "        # Create a DataFrame of features and importances\n",
    "        feature_importances = pd.DataFrame({\n",
    "            'feature': X_remaining.columns,\n",
    "            'importance': importances\n",
    "        })\n",
    "        \n",
    "        # Sort features by importance\n",
    "        feature_importances.sort_values(by='importance', ascending=True, inplace=True)\n",
    "        \n",
    "        # Remove the least important features based on step size\n",
    "        n_to_remove = min(step_num, X_remaining.shape[1] - min_features_to_select)\n",
    "        features_to_remove = feature_importances.head(n_to_remove)['feature'].tolist()\n",
    "        \n",
    "        # Drop the least important features\n",
    "        X_remaining.drop(columns=features_to_remove, inplace=True)\n",
    "    \n",
    "    # Convert history to a DataFrame for easy access\n",
    "    history_df = pd.DataFrame(history, columns=['n_features', 'cv_score'])\n",
    "    \n",
    "    # Identify the best cross-validation score and the corresponding feature sets with the least number of features\n",
    "    max_score = history_df['cv_score'].max()\n",
    "    best_idx = history_df[history_df['cv_score'] == max_score]['n_features'].idxmin()  # Minimize the number of features\n",
    "    \n",
    "    # The best selected features correspond to the maximum cross-validation score with the least features\n",
    "    best_features = feature_sets[best_idx]\n",
    "    \n",
    "    return best_features, history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting feature selection for Combined Dataset\n",
      "\n",
      "Handling missing data with SimpleImputer...\n",
      "\n",
      "Scaling features with MinMaxScaler...\n",
      "\n",
      "Applying SMOTE to balance the classes...\n",
      "Number of samples after SMOTE: 10930\n",
      "Class distribution after SMOTE: \n",
      "response\n",
      "0    5465\n",
      "1    5465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performing L1-based feature selection...\n",
      "Number of features after L1-based selection: 100\n",
      "\n",
      "Performing Mann-Whitney U Test feature selection with Bonferroni correction and parallelization...\n",
      "Number of features after Mann-Whitney U Test: 80\n",
      "Evaluating with 80 features...\n",
      "Evaluating with 72 features...\n",
      "Evaluating with 65 features...\n",
      "Evaluating with 59 features...\n",
      "Evaluating with 54 features...\n",
      "Evaluating with 49 features...\n",
      "Evaluating with 45 features...\n",
      "Evaluating with 41 features...\n",
      "Evaluating with 37 features...\n",
      "Evaluating with 34 features...\n",
      "Evaluating with 31 features...\n",
      "Early stopping, no significant improvement.\n",
      "Best Features: ['feature_3067', 'feature_4706', 'feature_5415', 'feature_7691', 'feature_7783', 'feature_8677', 'feature_9077', 'feature_9297', 'feature_9398', 'feature_9847', 'feature_10068', 'feature_10089', 'feature_10353', 'feature_11055', 'feature_11126', 'feature_11273', 'feature_11998', 'feature_12257', 'feature_14046', 'feature_14555', 'feature_14629', 'feature_14958', 'feature_15219', 'feature_15956', 'feature_17506', 'feature_18356', 'feature_19465', 'feature_19900', 'feature_19934', 'feature_20040', 'feature_20404', 'feature_20747', 'feature_21090', 'feature_21447', 'feature_21480', 'feature_22271', 'Menopause_(at_diagnosis)_\"{0_=_pre,\\n1_=_post,\\n2_=_N/A}\"_1', 'PR_\"{0_=_neg,\\n1_=_pos}\"_1', 'HER2_\"{0_=_neg,\\n1_=_pos,_2_=_borderline}\"_1', 'Staging(Metastasis)#(Mx_-replaced_by_-1)[M]_0', 'Tumor_Grade(M)\\n(Mitotic)_3']\n",
      "    n_features  cv_score\n",
      "0           80      0.99\n",
      "1           72      0.99\n",
      "2           65      0.99\n",
      "3           59      0.99\n",
      "4           54      0.99\n",
      "5           49      0.99\n",
      "6           45      0.99\n",
      "7           41      0.99\n",
      "8           37      0.98\n",
      "9           34      0.98\n",
      "10          31      0.97\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting the final features from the original datasets...\n",
      "\n",
      "Final datasets for 'Combined' stored with selected features.\n",
      "\n",
      "Starting feature selection for Clinical Dataset\n",
      "\n",
      "Skipping feature selection for 'Clinical' dataset. Retaining all original features.\n",
      "\n",
      "Starting feature selection for Image Dataset\n",
      "\n",
      "Handling missing data with SimpleImputer...\n",
      "\n",
      "Scaling features with MinMaxScaler...\n",
      "\n",
      "Applying SMOTE to balance the classes...\n",
      "Number of samples after SMOTE: 10930\n",
      "Class distribution after SMOTE: \n",
      "response\n",
      "0    5465\n",
      "1    5465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performing L1-based feature selection...\n",
      "Number of features after L1-based selection: 100\n",
      "\n",
      "Performing Mann-Whitney U Test feature selection with Bonferroni correction and parallelization...\n",
      "Number of features after Mann-Whitney U Test: 84\n",
      "Evaluating with 84 features...\n",
      "Evaluating with 76 features...\n",
      "Evaluating with 69 features...\n",
      "Evaluating with 63 features...\n",
      "Evaluating with 57 features...\n",
      "Evaluating with 52 features...\n",
      "Evaluating with 47 features...\n",
      "Evaluating with 43 features...\n",
      "Evaluating with 39 features...\n",
      "Evaluating with 36 features...\n",
      "Evaluating with 33 features...\n",
      "Early stopping, no significant improvement.\n",
      "Best Features: ['feature_3067', 'feature_3666', 'feature_4072', 'feature_4341', 'feature_4706', 'feature_5415', 'feature_6048', 'feature_7691', 'feature_7783', 'feature_8677', 'feature_9151', 'feature_9370', 'feature_9847', 'feature_9955', 'feature_10068', 'feature_10089', 'feature_10353', 'feature_11055', 'feature_11126', 'feature_11377', 'feature_11685', 'feature_11805', 'feature_11998', 'feature_12319', 'feature_12432', 'feature_12809', 'feature_12815', 'feature_13027', 'feature_13043', 'feature_13060', 'feature_13163', 'feature_13943', 'feature_14009', 'feature_14046', 'feature_14555', 'feature_14566', 'feature_14629', 'feature_14958', 'feature_15085', 'feature_15219', 'feature_15521', 'feature_17006', 'feature_17131', 'feature_17903', 'feature_18218', 'feature_18219', 'feature_19465', 'feature_19900', 'feature_19934', 'feature_20040', 'feature_20263', 'feature_20404', 'feature_20747', 'feature_21047', 'feature_21048', 'feature_21090', 'feature_21447', 'feature_21480', 'feature_22191', 'feature_22245', 'feature_22271', 'feature_22683', 'feature_23771']\n",
      "    n_features  cv_score\n",
      "0           84      0.98\n",
      "1           76      0.98\n",
      "2           69      0.98\n",
      "3           63      0.98\n",
      "4           57      0.97\n",
      "5           52      0.97\n",
      "6           47      0.96\n",
      "7           43      0.96\n",
      "8           39      0.95\n",
      "9           36      0.95\n",
      "10          33      0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting the final features from the original datasets...\n",
      "\n",
      "Final datasets for 'Image' stored with selected features.\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "selected_features_dict = {}\n",
    "\n",
    "apply_smote = True  # Set to False if you want to skip SMOTE\n",
    "apply_mannwhitney = True  # Set to False if you want to skip Mann-Whitney U Test\n",
    "\n",
    "for dataset_name in data_variations.keys():\n",
    "    \n",
    "    print(f\"\\nStarting feature selection for {dataset_name} Dataset\")\n",
    "\n",
    "    if dataset_name == 'Clinical':\n",
    "        print(\"\\nSkipping feature selection for 'Clinical' dataset. Retaining all original features.\")\n",
    "    else:\n",
    "        # Retrieve data\n",
    "        data = data_splits[dataset_name]\n",
    "\n",
    "        X_train_full = data['X_train_full']\n",
    "        y_train_full = data['y_train_full']\n",
    "        X_test_full = data['X_test_full']\n",
    "        y_test = data['y_test']\n",
    "        patient_ids_train = data['patient_ids_train']  # Preserving patient IDs\n",
    "        patient_ids_test = data['patient_ids_test']\n",
    "\n",
    "        # Handle Missing Data - Imputation\n",
    "        print(\"\\nHandling missing data with SimpleImputer...\")\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train_imputed = imputer.fit_transform(X_train_full)\n",
    "        X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_full.columns, index=X_train_full.index)\n",
    "\n",
    "        # Feature Scaling using MinMaxScaler\n",
    "        print(\"\\nScaling features with MinMaxScaler...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_full.columns, index=X_train_full.index)\n",
    "\n",
    "        if apply_smote:\n",
    "            # Apply SMOTE to balance the classes in the training data\n",
    "            print(\"\\nApplying SMOTE to balance the classes...\")\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train_full)\n",
    "\n",
    "            # Convert resampled data back to DataFrame with the original column names and reset indices\n",
    "            X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train_scaled.columns)\n",
    "            y_train_resampled = pd.Series(y_train_resampled)\n",
    "            print(f\"Number of samples after SMOTE: {X_train_resampled.shape[0]}\")\n",
    "            print(f\"Class distribution after SMOTE: \\n{y_train_resampled.value_counts()}\")\n",
    "\n",
    "            # Reset indices to ensure consistency\n",
    "            X_train_l1 = X_train_resampled.reset_index(drop=True)\n",
    "            y_train_resampled = y_train_resampled.reset_index(drop=True)\n",
    "        else:\n",
    "            print(\"\\nSkipping SMOTE. Using original training data.\")\n",
    "            X_train_l1 = X_train_scaled\n",
    "            y_train_resampled = y_train_full\n",
    "\n",
    "        # L1-based Feature Selection\n",
    "        print(\"\\nPerforming L1-based feature selection...\")\n",
    "        l1_selector = SelectFromModel(\n",
    "            LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000), max_features=100\n",
    "        )\n",
    "        l1_selector.fit(X_train_l1, y_train_resampled)\n",
    "        X_train_l1 = l1_selector.transform(X_train_l1)\n",
    "        X_train_l1 = pd.DataFrame(X_train_l1, columns=X_train_resampled.columns[l1_selector.get_support()])\n",
    "        print(f\"Number of features after L1-based selection: {X_train_l1.shape[1]}\")\n",
    "\n",
    "        if apply_mannwhitney:\n",
    "            # Mann-Whitney U Test Feature Selection with Parallelization\n",
    "            print(\"\\nPerforming Mann-Whitney U Test feature selection with Bonferroni correction and parallelization...\")\n",
    "            mannwhitney_selector = MannWhitneyUTestFeatureSelector(alpha=0.05, bonferroni=True, n_jobs=-1)\n",
    "            mannwhitney_selector.fit(X_train_l1, y_train_resampled)\n",
    "            X_train_mwu = mannwhitney_selector.transform(X_train_l1)\n",
    "            print(f\"Number of features after Mann-Whitney U Test: {X_train_mwu.shape[1]}\")\n",
    "        else:\n",
    "            print(\"\\nSkipping Mann-Whitney U Test. Using L1-selected features.\")\n",
    "            X_train_mwu = X_train_l1\n",
    "\n",
    "        # Manually perform RFECV using a Random Forest Classifier\n",
    "        rf_estimator = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=50, max_depth=7)\n",
    "        cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # Perform manual RFECV\n",
    "        best_features, rfecv_history = manual_rfecv(\n",
    "            X_train_mwu, y_train_resampled, rf_estimator, cv_strategy,\n",
    "            scoring='f1', min_features_to_select=5, step=0.1, early_stopping_rounds=10\n",
    "        )\n",
    "\n",
    "        print(f\"Best Features: {best_features}\")\n",
    "        print(rfecv_history)\n",
    "\n",
    "        # Plot the number of features vs. cross-validation score\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(rfecv_history['n_features'], rfecv_history['cv_score'], marker='o')\n",
    "        plt.xlabel(\"Number of Features Selected\")\n",
    "        plt.ylabel(\"Cross-validation F1 Score\")\n",
    "        plt.title(f\"Manual RFECV - {dataset_name}\")\n",
    "        plt.gca().invert_xaxis()  # Optional: Invert x-axis to show decreasing number of features\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Store the selected features\n",
    "        selected_features = best_features\n",
    "        selected_features_dict[dataset_name] = selected_features\n",
    "\n",
    "        # Select the final features from the original datasets\n",
    "        print(\"\\nSelecting the final features from the original datasets...\")\n",
    "\n",
    "        # Ensure that all selected features exist in the original datasets\n",
    "        missing_in_train = set(selected_features) - set(X_train_full.columns)\n",
    "        missing_in_test = set(selected_features) - set(X_test_full.columns)\n",
    "        if missing_in_train:\n",
    "            raise ValueError(f\"The following selected features are missing in X_train_full: {missing_in_train}\")\n",
    "        if missing_in_test:\n",
    "            raise ValueError(f\"The following selected features are missing in X_test_full: {missing_in_test}\")\n",
    "\n",
    "        # Subset the original X_train_full and X_test_full to include only the selected features\n",
    "        X_train_final = X_train_full[selected_features].copy()\n",
    "        X_test_final = X_test_full[selected_features].copy()\n",
    "\n",
    "        # Reset indices to ensure consistency\n",
    "        X_train_final.reset_index(drop=True, inplace=True)\n",
    "        y_train_full = y_train_full.reset_index(drop=True)\n",
    "        X_test_final.reset_index(drop=True, inplace=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        # Verify that the number of features matches\n",
    "        assert X_train_final.shape[1] == X_test_final.shape[1], \"Mismatch in number of features between training and test sets.\"\n",
    "        assert X_train_final.shape[0] == y_train_full.shape[0], \"Mismatch in number of rows between training X and Y.\"\n",
    "        assert X_test_final.shape[0] == y_test.shape[0], \"Mismatch in number of rows between test X and Y.\"\n",
    "\n",
    "        # Store the final datasets with selected features in data_splits\n",
    "        data_splits[dataset_name] = {\n",
    "            'X_train_full': X_train_final,\n",
    "            'X_test_full': X_test_final,\n",
    "            'y_train_full': y_train_full,\n",
    "            'y_test': y_test,\n",
    "            'patient_ids_train': patient_ids_train,  # Preserve patient IDs\n",
    "            'patient_ids_test': patient_ids_test\n",
    "        }\n",
    "\n",
    "        print(f\"\\nFinal datasets for '{dataset_name}' stored with selected features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers and param grid to evaluate\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    #'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='logloss', random_state=42, n_jobs=-1),\n",
    "    'LightGBM': lgb.LGBMClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42, max_iter=5000)\n",
    "}\n",
    "\n",
    "# Define classifiers to evaluate\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    #'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='logloss', random_state=42, n_jobs=-1),\n",
    "    'LightGBM': lgb.LGBMClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42, max_iter=5000)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1],\n",
    "        'classifier__max_depth': [3, 5, 7, 10]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1],\n",
    "        'classifier__num_leaves': [31, 63],\n",
    "        'classifier__verbose': [-1]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "        'classifier__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'classifier__n_estimators': [100, 150],\n",
    "        'classifier__learning_rate': [0.01, 0.1],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': np.logspace(-4, 4, 10),\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 5, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Nested Cross Validation for Hyperparameter Tuning\n",
    "\n",
    "def nested_cv_evaluation(dataset_name, X, y, groups, classifiers, param_grids, outer_splits=3, inner_splits=2):\n",
    "    \"\"\"\n",
    "    Performs nested cross-validation with hyperparameter tuning and group-aware splitting.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting Nested CV for {dataset_name} dataset...\")\n",
    "    outer_cv = StratifiedGroupKFold(n_splits=outer_splits, shuffle=True, random_state=42)\n",
    "    aggregated_scores = {}\n",
    "    best_estimators = {}\n",
    "    nested_scores = {name: [] for name in classifiers.keys()}\n",
    "    cv_results_all = {name: [] for name in classifiers.keys()}  # To store cv_results_\n",
    "\n",
    "    for name, classifier in classifiers.items():\n",
    "        print(f\"\\nEvaluating {name} on {dataset_name} dataset...\")\n",
    "        start_time = time.time()\n",
    "        scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "        best_estimators[name] = []\n",
    "        cv_results_list = []  # To collect cv_results_ from each outer fold\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y, groups=groups), 1):\n",
    "            print(f\"  Outer Fold {fold}/{outer_splits}\")\n",
    "            X_train_fold, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train_fold, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            groups_train_fold = groups.iloc[train_idx]\n",
    "\n",
    "            # Define the inner cross-validation with group awareness\n",
    "            inner_cv = StratifiedGroupKFold(n_splits=inner_splits, shuffle=True, random_state=42)\n",
    "\n",
    "            # Define the pipeline\n",
    "            pipeline = ImbPipeline(steps=[\n",
    "                ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "                ('scaler', MinMaxScaler()),\n",
    "                ('classifier', classifier)\n",
    "            ])\n",
    "\n",
    "            # Hyperparameter tuning with RandomizedSearchCV\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_distributions=param_grids[name],\n",
    "                scoring='f1',\n",
    "                n_iter=5,  # Adjusted for efficiency\n",
    "                cv=inner_cv.split(X_train_fold, y_train_fold, groups=groups_train_fold),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            # Fit the model on the training fold\n",
    "            search.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Get the best estimator\n",
    "            best_model = search.best_estimator_\n",
    "\n",
    "            # Evaluate on the validation fold\n",
    "            y_pred = best_model.predict(X_valid)\n",
    "\n",
    "            # Compute metrics\n",
    "            accuracy = accuracy_score(y_valid, y_pred)\n",
    "            precision = precision_score(y_valid, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_valid, y_pred)\n",
    "            f1 = f1_score(y_valid, y_pred)\n",
    "\n",
    "            # Append scores\n",
    "            scores['accuracy'].append(accuracy)\n",
    "            scores['precision'].append(precision)\n",
    "            scores['recall'].append(recall)\n",
    "            scores['f1'].append(f1)\n",
    "            nested_scores[name].append(f1)\n",
    "\n",
    "            # Store the best estimator\n",
    "            best_estimators[name].append(best_model)\n",
    "\n",
    "            # Collect cv_results_\n",
    "            cv_results = pd.DataFrame(search.cv_results_)\n",
    "            cv_results_list.append(cv_results)\n",
    "\n",
    "        # Aggregate scores\n",
    "        aggregated_scores[name] = {metric: (np.mean(scores[metric]), np.std(scores[metric])) for metric in scores}\n",
    "\n",
    "        # Combine cv_results_ from all outer folds\n",
    "        cv_results_all[name] = pd.concat(cv_results_list, ignore_index=True)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"{name} - Completed in {elapsed_time:.2f} seconds\")\n",
    "        print(f\"Aggregated Scores for {name}: {aggregated_scores[name]}\")\n",
    "\n",
    "    return aggregated_scores, best_estimators, nested_scores, cv_results_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Nested Cross-Validation for Combined Dataset\n",
      "\n",
      "Starting Nested CV for Combined dataset...\n",
      "\n",
      "Evaluating Logistic Regression on Combined dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "Logistic Regression - Completed in 9.79 seconds\n",
      "Aggregated Scores for Logistic Regression: {'accuracy': (np.float64(0.8539813255321445), np.float64(0.027019170234241954)), 'precision': (np.float64(0.6217684322025983), np.float64(0.09231608896581815)), 'recall': (np.float64(0.7890595036102287), np.float64(0.09345378170426634)), 'f1': (np.float64(0.6862611365931697), np.float64(0.05690057451369806))}\n",
      "\n",
      "Evaluating Random Forest on Combined dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "Random Forest - Completed in 5.42 seconds\n",
      "Aggregated Scores for Random Forest: {'accuracy': (np.float64(0.8231052091218203), np.float64(0.01778522472639224)), 'precision': (np.float64(0.6523382319587537), np.float64(0.17540786137673395)), 'recall': (np.float64(0.2871759116210093), np.float64(0.0655780476658333)), 'f1': (np.float64(0.39591709370219724), np.float64(0.08776098679963522))}\n",
      "\n",
      "Evaluating XGBoost on Combined dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "XGBoost - Completed in 9.82 seconds\n",
      "Aggregated Scores for XGBoost: {'accuracy': (np.float64(0.8076939397973536), np.float64(0.03850988473096255)), 'precision': (np.float64(0.5491356862812595), np.float64(0.14758635644488552)), 'recall': (np.float64(0.5263137106798823), np.float64(0.08106183036432885)), 'f1': (np.float64(0.5279023075323718), np.float64(0.09651707916993678))}\n",
      "\n",
      "Evaluating LightGBM on Combined dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "LightGBM - Completed in 56.69 seconds\n",
      "Aggregated Scores for LightGBM: {'accuracy': (np.float64(0.7817265407383392), np.float64(0.046634859951253556)), 'precision': (np.float64(0.45502036842944316), np.float64(0.05912838948613379)), 'recall': (np.float64(0.4249351763667996), np.float64(0.15017285917766668)), 'f1': (np.float64(0.4343846411638174), np.float64(0.10599403893693925))}\n",
      "\n",
      "Evaluating SVM on Combined dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "SVM - Completed in 18.86 seconds\n",
      "Aggregated Scores for SVM: {'accuracy': (np.float64(0.8552224850082789), np.float64(0.02460699835641556)), 'precision': (np.float64(0.6206679459186207), np.float64(0.09386700295640484)), 'recall': (np.float64(0.8177372204429557), np.float64(0.08262846229648467)), 'f1': (np.float64(0.6960246749393374), np.float64(0.04920791292584383))}\n",
      "\n",
      "Starting Nested Cross-Validation for Clinical Dataset\n",
      "\n",
      "Starting Nested CV for Clinical dataset...\n",
      "\n",
      "Evaluating Logistic Regression on Clinical dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "Logistic Regression - Completed in 0.39 seconds\n",
      "Aggregated Scores for Logistic Regression: {'accuracy': (np.float64(0.6935127674258109), np.float64(0.04318224953867822)), 'precision': (np.float64(0.3601851851851852), np.float64(0.048661790161003374)), 'recall': (np.float64(0.3761437908496732), np.float64(0.0919700976837405)), 'f1': (np.float64(0.35555555555555557), np.float64(0.037761918007477815))}\n",
      "\n",
      "Evaluating Random Forest on Clinical dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "Random Forest - Completed in 2.46 seconds\n",
      "Aggregated Scores for Random Forest: {'accuracy': (np.float64(0.6602484472049689), np.float64(0.01840438806214788)), 'precision': (np.float64(0.22058643111274692), np.float64(0.09348079270111422)), 'recall': (np.float64(0.20482026143790852), np.float64(0.10264826310800855)), 'f1': (np.float64(0.20976800976800977), np.float64(0.09425686565542353))}\n",
      "\n",
      "Evaluating XGBoost on Clinical dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "XGBoost - Completed in 0.83 seconds\n",
      "Aggregated Scores for XGBoost: {'accuracy': (np.float64(0.6982056590752244), np.float64(0.05336485500907122)), 'precision': (np.float64(0.3355455002513826), np.float64(0.14442224442076843)), 'recall': (np.float64(0.3079248366013072), np.float64(0.12819046615407284)), 'f1': (np.float64(0.3191919191919192), np.float64(0.13179399135596034))}\n",
      "\n",
      "Evaluating LightGBM on Clinical dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "LightGBM - Completed in 6.64 seconds\n",
      "Aggregated Scores for LightGBM: {'accuracy': (np.float64(0.6889579020013802), np.float64(0.041195568028237727)), 'precision': (np.float64(0.3503455608718766), np.float64(0.07905424899709136)), 'recall': (np.float64(0.35776143790849674), np.float64(0.0773724299005164)), 'f1': (np.float64(0.3439153439153439), np.float64(0.04314684240820131))}\n",
      "\n",
      "Evaluating SVM on Clinical dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "SVM - Completed in 0.43 seconds\n",
      "Aggregated Scores for SVM: {'accuracy': (np.float64(0.7032436162870946), np.float64(0.028072647603976975)), 'precision': (np.float64(0.33867521367521364), np.float64(0.027736655952451214)), 'recall': (np.float64(0.29648692810457516), np.float64(0.12190686877889363)), 'f1': (np.float64(0.30185185185185187), np.float64(0.06191945739740922))}\n",
      "\n",
      "Starting Nested Cross-Validation for Image Dataset\n",
      "\n",
      "Starting Nested CV for Image dataset...\n",
      "\n",
      "Evaluating Logistic Regression on Image dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "Logistic Regression - Completed in 1.42 seconds\n",
      "Aggregated Scores for Logistic Regression: {'accuracy': (np.float64(0.8627351021694946), np.float64(0.020429772466623093)), 'precision': (np.float64(0.630245854307825), np.float64(0.091273338470907)), 'recall': (np.float64(0.7525224615025237), np.float64(0.06968182363574672)), 'f1': (np.float64(0.685044984781268), np.float64(0.08210279745752945))}\n",
      "\n",
      "Evaluating Random Forest on Image dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "Random Forest - Completed in 7.41 seconds\n",
      "Aggregated Scores for Random Forest: {'accuracy': (np.float64(0.8092517318661914), np.float64(0.02710864684668719)), 'precision': (np.float64(0.6256307435254803), np.float64(0.1535337900378989)), 'recall': (np.float64(0.18188415941116123), np.float64(0.027445207391095433)), 'f1': (np.float64(0.28129670490203945), np.float64(0.04893406178743574))}\n",
      "\n",
      "Evaluating XGBoost on Image dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "XGBoost - Completed in 18.37 seconds\n",
      "Aggregated Scores for XGBoost: {'accuracy': (np.float64(0.7592494234581593), np.float64(0.04676732022251187)), 'precision': (np.float64(0.40556301921555304), np.float64(0.036895753752985434)), 'recall': (np.float64(0.33868424568358807), np.float64(0.05418326599148737)), 'f1': (np.float64(0.36496996334786475), np.float64(0.029077463591689372))}\n",
      "\n",
      "Evaluating LightGBM on Image dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "LightGBM - Completed in 66.03 seconds\n",
      "Aggregated Scores for LightGBM: {'accuracy': (np.float64(0.7817358136662459), np.float64(0.05827787507933089)), 'precision': (np.float64(0.5015825048540855), np.float64(0.15622372251970887)), 'recall': (np.float64(0.2674446882259676), np.float64(0.05557518363317438)), 'f1': (np.float64(0.3365315183164153), np.float64(0.044099126909058296))}\n",
      "\n",
      "Evaluating SVM on Image dataset...\n",
      "  Outer Fold 1/3\n",
      "  Outer Fold 2/3\n",
      "  Outer Fold 3/3\n",
      "SVM - Completed in 26.38 seconds\n",
      "Aggregated Scores for SVM: {'accuracy': (np.float64(0.8620710159070507), np.float64(0.02219881225876544)), 'precision': (np.float64(0.6323130356939496), np.float64(0.09352389520980084)), 'recall': (np.float64(0.7564474258784131), np.float64(0.054576116258655966)), 'f1': (np.float64(0.6869942419116652), np.float64(0.07632268397639475))}\n"
     ]
    }
   ],
   "source": [
    "# Collect nested CV results\n",
    "\n",
    "nested_cv_results = {}  # To store nested CV results\n",
    "for dataset_name in data_variations.keys():\n",
    "    print(f\"\\nStarting Nested Cross-Validation for {dataset_name} Dataset\")\n",
    "\n",
    "    # Retrieve data\n",
    "    data = data_splits[dataset_name]\n",
    "    X_train_full = data['X_train_full']\n",
    "    y_train_full = data['y_train_full']\n",
    "    groups_train = data['patient_ids_train']\n",
    "\n",
    "    # Perform nested cross-validation\n",
    "    aggregated_scores, best_estimators, nested_scores, cv_results_all = nested_cv_evaluation(\n",
    "        dataset_name, X_train_full, y_train_full, groups_train, classifiers, param_grids\n",
    "    )\n",
    "\n",
    "    # Store the results\n",
    "    nested_cv_results[dataset_name] = {\n",
    "        'aggregated_scores': aggregated_scores,\n",
    "        'best_estimators': best_estimators,\n",
    "        'nested_scores': nested_scores,\n",
    "        'cv_results_all': cv_results_all\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retraining and Evaluating Models for Combined Dataset\n",
      "\n",
      "Retraining Logistic Regression on Combined dataset...\n",
      "Logistic Regression Test Results on Combined Dataset:\n",
      "Accuracy: 0.7436\n",
      "Precision: 0.4682\n",
      "Recall: 0.4847\n",
      "F1 Score: 0.4763\n",
      "ROC AUC Score: 0.7035\n",
      "Confusion Matrix:\n",
      "[[1108  234]\n",
      " [ 219  206]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1342\n",
      "           1       0.47      0.48      0.48       425\n",
      "\n",
      "    accuracy                           0.74      1767\n",
      "   macro avg       0.65      0.66      0.65      1767\n",
      "weighted avg       0.75      0.74      0.75      1767\n",
      "\n",
      "\n",
      "Retraining Random Forest on Combined dataset...\n",
      "Random Forest Test Results on Combined Dataset:\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.4574\n",
      "Recall: 0.1012\n",
      "F1 Score: 0.1657\n",
      "ROC AUC Score: 0.7467\n",
      "Confusion Matrix:\n",
      "[[1291   51]\n",
      " [ 382   43]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1342\n",
      "           1       0.46      0.10      0.17       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.61      0.53      0.51      1767\n",
      "weighted avg       0.70      0.75      0.69      1767\n",
      "\n",
      "\n",
      "Retraining XGBoost on Combined dataset...\n",
      "XGBoost Test Results on Combined Dataset:\n",
      "Accuracy: 0.7521\n",
      "Precision: 0.4711\n",
      "Recall: 0.2494\n",
      "F1 Score: 0.3262\n",
      "ROC AUC Score: 0.7077\n",
      "Confusion Matrix:\n",
      "[[1223  119]\n",
      " [ 319  106]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85      1342\n",
      "           1       0.47      0.25      0.33       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.63      0.58      0.59      1767\n",
      "weighted avg       0.72      0.75      0.72      1767\n",
      "\n",
      "\n",
      "Retraining LightGBM on Combined dataset...\n",
      "LightGBM Test Results on Combined Dataset:\n",
      "Accuracy: 0.7487\n",
      "Precision: 0.4345\n",
      "Recall: 0.1482\n",
      "F1 Score: 0.2211\n",
      "ROC AUC Score: 0.7190\n",
      "Confusion Matrix:\n",
      "[[1260   82]\n",
      " [ 362   63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1342\n",
      "           1       0.43      0.15      0.22       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.61      0.54      0.54      1767\n",
      "weighted avg       0.69      0.75      0.70      1767\n",
      "\n",
      "\n",
      "Retraining SVM on Combined dataset...\n",
      "SVM Test Results on Combined Dataset:\n",
      "Accuracy: 0.7572\n",
      "Precision: 0.4956\n",
      "Recall: 0.5294\n",
      "F1 Score: 0.5119\n",
      "ROC AUC Score: 0.7157\n",
      "Confusion Matrix:\n",
      "[[1113  229]\n",
      " [ 200  225]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      1342\n",
      "           1       0.50      0.53      0.51       425\n",
      "\n",
      "    accuracy                           0.76      1767\n",
      "   macro avg       0.67      0.68      0.68      1767\n",
      "weighted avg       0.76      0.76      0.76      1767\n",
      "\n",
      "\n",
      "Retraining and Evaluating Models for Clinical Dataset\n",
      "\n",
      "Retraining Logistic Regression on Clinical dataset...\n",
      "Logistic Regression Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7170\n",
      "Precision: 0.3636\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3478\n",
      "ROC AUC Score: 0.6829\n",
      "Confusion Matrix:\n",
      "[[34  7]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        41\n",
      "           1       0.36      0.33      0.35        12\n",
      "\n",
      "    accuracy                           0.72        53\n",
      "   macro avg       0.59      0.58      0.58        53\n",
      "weighted avg       0.71      0.72      0.71        53\n",
      "\n",
      "\n",
      "Retraining Random Forest on Clinical dataset...\n",
      "Random Forest Test Results on Clinical Dataset:\n",
      "Accuracy: 0.6792\n",
      "Precision: 0.2727\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2609\n",
      "ROC AUC Score: 0.6545\n",
      "Confusion Matrix:\n",
      "[[33  8]\n",
      " [ 9  3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80        41\n",
      "           1       0.27      0.25      0.26        12\n",
      "\n",
      "    accuracy                           0.68        53\n",
      "   macro avg       0.53      0.53      0.53        53\n",
      "weighted avg       0.67      0.68      0.67        53\n",
      "\n",
      "\n",
      "Retraining XGBoost on Clinical dataset...\n",
      "XGBoost Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7358\n",
      "Precision: 0.4000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3636\n",
      "ROC AUC Score: 0.6707\n",
      "Confusion Matrix:\n",
      "[[35  6]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        41\n",
      "           1       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.61      0.59      0.60        53\n",
      "weighted avg       0.72      0.74      0.73        53\n",
      "\n",
      "\n",
      "Retraining LightGBM on Clinical dataset...\n",
      "LightGBM Test Results on Clinical Dataset:\n",
      "Accuracy: 0.6792\n",
      "Precision: 0.2727\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2609\n",
      "ROC AUC Score: 0.6077\n",
      "Confusion Matrix:\n",
      "[[33  8]\n",
      " [ 9  3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80        41\n",
      "           1       0.27      0.25      0.26        12\n",
      "\n",
      "    accuracy                           0.68        53\n",
      "   macro avg       0.53      0.53      0.53        53\n",
      "weighted avg       0.67      0.68      0.67        53\n",
      "\n",
      "\n",
      "Retraining SVM on Clinical dataset...\n",
      "SVM Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7547\n",
      "Precision: 0.4545\n",
      "Recall: 0.4167\n",
      "F1 Score: 0.4348\n",
      "ROC AUC Score: 0.6890\n",
      "Confusion Matrix:\n",
      "[[35  6]\n",
      " [ 7  5]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        41\n",
      "           1       0.45      0.42      0.43        12\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.64      0.64      0.64        53\n",
      "weighted avg       0.75      0.75      0.75        53\n",
      "\n",
      "\n",
      "Retraining and Evaluating Models for Image Dataset\n",
      "\n",
      "Retraining Logistic Regression on Image dataset...\n",
      "Logistic Regression Test Results on Image Dataset:\n",
      "Accuracy: 0.6055\n",
      "Precision: 0.1808\n",
      "Recall: 0.1812\n",
      "F1 Score: 0.1810\n",
      "ROC AUC Score: 0.4876\n",
      "Confusion Matrix:\n",
      "[[993 349]\n",
      " [348  77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1342\n",
      "           1       0.18      0.18      0.18       425\n",
      "\n",
      "    accuracy                           0.61      1767\n",
      "   macro avg       0.46      0.46      0.46      1767\n",
      "weighted avg       0.61      0.61      0.61      1767\n",
      "\n",
      "\n",
      "Retraining Random Forest on Image dataset...\n",
      "Random Forest Test Results on Image Dataset:\n",
      "Accuracy: 0.7380\n",
      "Precision: 0.3443\n",
      "Recall: 0.0988\n",
      "F1 Score: 0.1536\n",
      "ROC AUC Score: 0.5482\n",
      "Confusion Matrix:\n",
      "[[1262   80]\n",
      " [ 383   42]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.84      1342\n",
      "           1       0.34      0.10      0.15       425\n",
      "\n",
      "    accuracy                           0.74      1767\n",
      "   macro avg       0.56      0.52      0.50      1767\n",
      "weighted avg       0.67      0.74      0.68      1767\n",
      "\n",
      "\n",
      "Retraining XGBoost on Image dataset...\n",
      "XGBoost Test Results on Image Dataset:\n",
      "Accuracy: 0.6689\n",
      "Precision: 0.2333\n",
      "Recall: 0.1647\n",
      "F1 Score: 0.1931\n",
      "ROC AUC Score: 0.5318\n",
      "Confusion Matrix:\n",
      "[[1112  230]\n",
      " [ 355   70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      1342\n",
      "           1       0.23      0.16      0.19       425\n",
      "\n",
      "    accuracy                           0.67      1767\n",
      "   macro avg       0.50      0.50      0.49      1767\n",
      "weighted avg       0.63      0.67      0.65      1767\n",
      "\n",
      "\n",
      "Retraining LightGBM on Image dataset...\n",
      "LightGBM Test Results on Image Dataset:\n",
      "Accuracy: 0.7176\n",
      "Precision: 0.2921\n",
      "Recall: 0.1224\n",
      "F1 Score: 0.1725\n",
      "ROC AUC Score: 0.5189\n",
      "Confusion Matrix:\n",
      "[[1216  126]\n",
      " [ 373   52]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      1342\n",
      "           1       0.29      0.12      0.17       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.53      0.51      0.50      1767\n",
      "weighted avg       0.65      0.72      0.67      1767\n",
      "\n",
      "\n",
      "Retraining SVM on Image dataset...\n",
      "SVM Test Results on Image Dataset:\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.2050\n",
      "Recall: 0.2118\n",
      "F1 Score: 0.2083\n",
      "ROC AUC Score: 0.4999\n",
      "Confusion Matrix:\n",
      "[[993 349]\n",
      " [335  90]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1342\n",
      "           1       0.21      0.21      0.21       425\n",
      "\n",
      "    accuracy                           0.61      1767\n",
      "   macro avg       0.48      0.48      0.48      1767\n",
      "weighted avg       0.62      0.61      0.62      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain Models on Entire Training Set Using Best Hyperparameters and Evaluate on Test Set\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.base import clone\n",
    "\n",
    "test_results = {}  # To store test set results\n",
    "\n",
    "for dataset_name in data_splits.keys():\n",
    "    print(f\"\\nRetraining and Evaluating Models for {dataset_name} Dataset\")\n",
    "    \n",
    "    # Retrieve data splits for the current dataset\n",
    "    data = data_splits[dataset_name]\n",
    "    X_train_full = data['X_train_full']\n",
    "    y_train_full = data['y_train_full']\n",
    "    X_test_full = data['X_test_full']\n",
    "    y_test = data['y_test']\n",
    "    groups_train = data['patient_ids_train']\n",
    "    groups_test = data['patient_ids_test']\n",
    "    \n",
    "    # Reset indices to ensure consistency\n",
    "    X_train_full = X_train_full.reset_index(drop=True)\n",
    "    y_train_full = y_train_full.reset_index(drop=True)\n",
    "    X_test_full = X_test_full.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    # Get nested CV results for the current dataset\n",
    "    nested_results = nested_cv_results[dataset_name]\n",
    "    cv_results_all = nested_results['cv_results_all']\n",
    "    \n",
    "    test_results[dataset_name] = {}  # Initialize dictionary to store test results for each classifier\n",
    "    \n",
    "    for classifier_name in classifiers.keys():\n",
    "        print(f\"\\nRetraining {classifier_name} on {dataset_name} dataset...\")\n",
    "        \n",
    "        # Get cross-validation results for the current classifier\n",
    "        cv_results = cv_results_all[classifier_name]\n",
    "        \n",
    "        # Find the hyperparameters with the best mean_test_score (which is F1 score)\n",
    "        max_mean_test_score = cv_results['mean_test_score'].max()\n",
    "        best_rows = cv_results[cv_results['mean_test_score'] == max_mean_test_score]\n",
    "        \n",
    "        # If multiple rows have the same max score, pick the first one\n",
    "        best_row = best_rows.iloc[0]\n",
    "        \n",
    "        # Extract the best hyperparameters from the pipeline parameters\n",
    "        best_params = best_row['params']\n",
    "        \n",
    "        # The params are for the entire pipeline; extract classifier's hyperparameters\n",
    "        classifier_params = {}\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name.startswith('classifier__'):\n",
    "                # Remove 'classifier__' prefix to get the parameter name\n",
    "                param_short = param_name.replace('classifier__', '')\n",
    "                classifier_params[param_short] = param_value\n",
    "        \n",
    "        # Get the default classifier with default parameters\n",
    "        default_classifier = classifiers[classifier_name]\n",
    "        \n",
    "        # Clone the default classifier to avoid modifying the original\n",
    "        classifier = clone(default_classifier)\n",
    "        \n",
    "        # Update the classifier's parameters with the best hyperparameters\n",
    "        classifier.set_params(**classifier_params)\n",
    "        \n",
    "        # Handle compatibility between solver and penalty for Logistic Regression\n",
    "        if classifier_name == 'Logistic Regression':\n",
    "            penalty = classifier.get_params().get('penalty', 'l2')\n",
    "            solver = classifier.get_params().get('solver', 'lbfgs')\n",
    "            if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "                # Change solver to 'liblinear' if penalty is 'l1'\n",
    "                classifier.set_params(solver='liblinear')\n",
    "                print(f\"Adjusted solver to 'liblinear' for 'l1' penalty.\")\n",
    "            elif penalty == 'elasticnet' and solver != 'saga':\n",
    "                # 'elasticnet' penalty requires 'saga' solver\n",
    "                classifier.set_params(solver='saga')\n",
    "                print(f\"Adjusted solver to 'saga' for 'elasticnet' penalty.\")\n",
    "            elif penalty == 'l2' and solver == 'liblinear' and classifier.get_params().get('dual', False):\n",
    "                # Dual formulation is only implemented for l2 penalty with liblinear solver\n",
    "                classifier.set_params(dual=True)\n",
    "            else:\n",
    "                # Ensure dual is False for other solvers\n",
    "                classifier.set_params(dual=False)\n",
    "        \n",
    "        # Define the pipeline with SMOTE, scaling, and the classifier\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        \n",
    "        # Fit the pipeline on the entire training set\n",
    "        pipeline.fit(X_train_full, y_train_full)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = pipeline.predict(X_test_full)\n",
    "        \n",
    "        # Get predicted probabilities if available\n",
    "        y_proba = pipeline.predict_proba(X_test_full)[:, 1] if hasattr(pipeline, \"predict_proba\") else None\n",
    "        \n",
    "        # Compute performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        # Store the test results\n",
    "        test_results[dataset_name][classifier_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "        \n",
    "        # Print the results\n",
    "        print(f\"{classifier_name} Test Results on {dataset_name} Dataset:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        if roc_auc is not None:\n",
    "            print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"Classification Report:\")\n",
    "        print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results for Combined Dataset:\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.7436\n",
      "Precision: 0.4682\n",
      "Recall: 0.4847\n",
      "F1 Score: 0.4763\n",
      "ROC AUC Score: 0.7035\n",
      "Confusion Matrix:\n",
      "[[1108  234]\n",
      " [ 219  206]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1342\n",
      "           1       0.47      0.48      0.48       425\n",
      "\n",
      "    accuracy                           0.74      1767\n",
      "   macro avg       0.65      0.66      0.65      1767\n",
      "weighted avg       0.75      0.74      0.75      1767\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.4574\n",
      "Recall: 0.1012\n",
      "F1 Score: 0.1657\n",
      "ROC AUC Score: 0.7467\n",
      "Confusion Matrix:\n",
      "[[1291   51]\n",
      " [ 382   43]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1342\n",
      "           1       0.46      0.10      0.17       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.61      0.53      0.51      1767\n",
      "weighted avg       0.70      0.75      0.69      1767\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.7521\n",
      "Precision: 0.4711\n",
      "Recall: 0.2494\n",
      "F1 Score: 0.3262\n",
      "ROC AUC Score: 0.7077\n",
      "Confusion Matrix:\n",
      "[[1223  119]\n",
      " [ 319  106]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85      1342\n",
      "           1       0.47      0.25      0.33       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.63      0.58      0.59      1767\n",
      "weighted avg       0.72      0.75      0.72      1767\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Accuracy: 0.7487\n",
      "Precision: 0.4345\n",
      "Recall: 0.1482\n",
      "F1 Score: 0.2211\n",
      "ROC AUC Score: 0.7190\n",
      "Confusion Matrix:\n",
      "[[1260   82]\n",
      " [ 362   63]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1342\n",
      "           1       0.43      0.15      0.22       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.61      0.54      0.54      1767\n",
      "weighted avg       0.69      0.75      0.70      1767\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.7572\n",
      "Precision: 0.4956\n",
      "Recall: 0.5294\n",
      "F1 Score: 0.5119\n",
      "ROC AUC Score: 0.7157\n",
      "Confusion Matrix:\n",
      "[[1113  229]\n",
      " [ 200  225]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      1342\n",
      "           1       0.50      0.53      0.51       425\n",
      "\n",
      "    accuracy                           0.76      1767\n",
      "   macro avg       0.67      0.68      0.68      1767\n",
      "weighted avg       0.76      0.76      0.76      1767\n",
      "\n",
      "\n",
      "Test Results for Clinical Dataset:\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.7170\n",
      "Precision: 0.3636\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3478\n",
      "ROC AUC Score: 0.6829\n",
      "Confusion Matrix:\n",
      "[[34  7]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        41\n",
      "           1       0.36      0.33      0.35        12\n",
      "\n",
      "    accuracy                           0.72        53\n",
      "   macro avg       0.59      0.58      0.58        53\n",
      "weighted avg       0.71      0.72      0.71        53\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.6792\n",
      "Precision: 0.2727\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2609\n",
      "ROC AUC Score: 0.6545\n",
      "Confusion Matrix:\n",
      "[[33  8]\n",
      " [ 9  3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80        41\n",
      "           1       0.27      0.25      0.26        12\n",
      "\n",
      "    accuracy                           0.68        53\n",
      "   macro avg       0.53      0.53      0.53        53\n",
      "weighted avg       0.67      0.68      0.67        53\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.7358\n",
      "Precision: 0.4000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3636\n",
      "ROC AUC Score: 0.6707\n",
      "Confusion Matrix:\n",
      "[[35  6]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        41\n",
      "           1       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.61      0.59      0.60        53\n",
      "weighted avg       0.72      0.74      0.73        53\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Accuracy: 0.6792\n",
      "Precision: 0.2727\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2609\n",
      "ROC AUC Score: 0.6077\n",
      "Confusion Matrix:\n",
      "[[33  8]\n",
      " [ 9  3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80        41\n",
      "           1       0.27      0.25      0.26        12\n",
      "\n",
      "    accuracy                           0.68        53\n",
      "   macro avg       0.53      0.53      0.53        53\n",
      "weighted avg       0.67      0.68      0.67        53\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.7547\n",
      "Precision: 0.4545\n",
      "Recall: 0.4167\n",
      "F1 Score: 0.4348\n",
      "ROC AUC Score: 0.6890\n",
      "Confusion Matrix:\n",
      "[[35  6]\n",
      " [ 7  5]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        41\n",
      "           1       0.45      0.42      0.43        12\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.64      0.64      0.64        53\n",
      "weighted avg       0.75      0.75      0.75        53\n",
      "\n",
      "\n",
      "Test Results for Image Dataset:\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.6055\n",
      "Precision: 0.1808\n",
      "Recall: 0.1812\n",
      "F1 Score: 0.1810\n",
      "ROC AUC Score: 0.4876\n",
      "Confusion Matrix:\n",
      "[[993 349]\n",
      " [348  77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1342\n",
      "           1       0.18      0.18      0.18       425\n",
      "\n",
      "    accuracy                           0.61      1767\n",
      "   macro avg       0.46      0.46      0.46      1767\n",
      "weighted avg       0.61      0.61      0.61      1767\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.7380\n",
      "Precision: 0.3443\n",
      "Recall: 0.0988\n",
      "F1 Score: 0.1536\n",
      "ROC AUC Score: 0.5482\n",
      "Confusion Matrix:\n",
      "[[1262   80]\n",
      " [ 383   42]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.84      1342\n",
      "           1       0.34      0.10      0.15       425\n",
      "\n",
      "    accuracy                           0.74      1767\n",
      "   macro avg       0.56      0.52      0.50      1767\n",
      "weighted avg       0.67      0.74      0.68      1767\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Accuracy: 0.6689\n",
      "Precision: 0.2333\n",
      "Recall: 0.1647\n",
      "F1 Score: 0.1931\n",
      "ROC AUC Score: 0.5318\n",
      "Confusion Matrix:\n",
      "[[1112  230]\n",
      " [ 355   70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      1342\n",
      "           1       0.23      0.16      0.19       425\n",
      "\n",
      "    accuracy                           0.67      1767\n",
      "   macro avg       0.50      0.50      0.49      1767\n",
      "weighted avg       0.63      0.67      0.65      1767\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Accuracy: 0.7176\n",
      "Precision: 0.2921\n",
      "Recall: 0.1224\n",
      "F1 Score: 0.1725\n",
      "ROC AUC Score: 0.5189\n",
      "Confusion Matrix:\n",
      "[[1216  126]\n",
      " [ 373   52]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83      1342\n",
      "           1       0.29      0.12      0.17       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.53      0.51      0.50      1767\n",
      "weighted avg       0.65      0.72      0.67      1767\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Accuracy: 0.6129\n",
      "Precision: 0.2050\n",
      "Recall: 0.2118\n",
      "F1 Score: 0.2083\n",
      "ROC AUC Score: 0.4999\n",
      "Confusion Matrix:\n",
      "[[993 349]\n",
      " [335  90]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1342\n",
      "           1       0.21      0.21      0.21       425\n",
      "\n",
      "    accuracy                           0.61      1767\n",
      "   macro avg       0.48      0.48      0.48      1767\n",
      "weighted avg       0.62      0.61      0.62      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying Comprehensive Performance Metrics for Each Model on Test Set\n",
    "\n",
    "for dataset_name, classifiers_results in test_results.items():\n",
    "    print(f\"\\nTest Results for {dataset_name} Dataset:\")\n",
    "    for classifier_name, metrics in classifiers_results.items():\n",
    "        print(f\"\\nClassifier: {classifier_name}\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "        if metrics['roc_auc'] is not None:\n",
    "            print(f\"ROC AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(metrics['confusion_matrix'])\n",
    "        print(\"Classification Report:\")\n",
    "        print(metrics['classification_report'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusting Thresholds for Combined Dataset:\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Optimal Threshold (Youden's J): 0.1574\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.6899\n",
      "Precision: 0.4105\n",
      "Recall: 0.6635\n",
      "F1 Score: 0.5072\n",
      "ROC AUC Score: 0.7035\n",
      "Confusion Matrix:\n",
      "[[937 405]\n",
      " [143 282]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.77      1342\n",
      "           1       0.41      0.66      0.51       425\n",
      "\n",
      "    accuracy                           0.69      1767\n",
      "   macro avg       0.64      0.68      0.64      1767\n",
      "weighted avg       0.76      0.69      0.71      1767\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Optimal Threshold (Youden's J): 0.2824\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.7550\n",
      "Precision: 0.4933\n",
      "Recall: 0.6941\n",
      "F1 Score: 0.5767\n",
      "ROC AUC Score: 0.7467\n",
      "Confusion Matrix:\n",
      "[[1039  303]\n",
      " [ 130  295]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83      1342\n",
      "           1       0.49      0.69      0.58       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.69      0.73      0.70      1767\n",
      "weighted avg       0.79      0.75      0.77      1767\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Optimal Threshold (Youden's J): 0.1659\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.6525\n",
      "Precision: 0.3857\n",
      "Recall: 0.7506\n",
      "F1 Score: 0.5096\n",
      "ROC AUC Score: 0.7077\n",
      "Confusion Matrix:\n",
      "[[834 508]\n",
      " [106 319]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73      1342\n",
      "           1       0.39      0.75      0.51       425\n",
      "\n",
      "    accuracy                           0.65      1767\n",
      "   macro avg       0.64      0.69      0.62      1767\n",
      "weighted avg       0.77      0.65      0.68      1767\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Optimal Threshold (Youden's J): 0.0022\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.7057\n",
      "Precision: 0.4313\n",
      "Recall: 0.7012\n",
      "F1 Score: 0.5341\n",
      "ROC AUC Score: 0.7190\n",
      "Confusion Matrix:\n",
      "[[949 393]\n",
      " [127 298]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78      1342\n",
      "           1       0.43      0.70      0.53       425\n",
      "\n",
      "    accuracy                           0.71      1767\n",
      "   macro avg       0.66      0.70      0.66      1767\n",
      "weighted avg       0.77      0.71      0.72      1767\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Optimal Threshold (Youden's J): 0.1983\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.7176\n",
      "Precision: 0.4420\n",
      "Recall: 0.6635\n",
      "F1 Score: 0.5306\n",
      "ROC AUC Score: 0.7157\n",
      "Confusion Matrix:\n",
      "[[986 356]\n",
      " [143 282]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.80      1342\n",
      "           1       0.44      0.66      0.53       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.66      0.70      0.66      1767\n",
      "weighted avg       0.77      0.72      0.73      1767\n",
      "\n",
      "\n",
      "Adjusting Thresholds for Clinical Dataset:\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Optimal Threshold (Youden's J): 0.2382\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.6226\n",
      "Precision: 0.3571\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.5000\n",
      "ROC AUC Score: 0.6829\n",
      "Confusion Matrix:\n",
      "[[23 18]\n",
      " [ 2 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.56      0.70        41\n",
      "           1       0.36      0.83      0.50        12\n",
      "\n",
      "    accuracy                           0.62        53\n",
      "   macro avg       0.64      0.70      0.60        53\n",
      "weighted avg       0.79      0.62      0.65        53\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Optimal Threshold (Youden's J): 0.2249\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.5472\n",
      "Precision: 0.3333\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.5000\n",
      "ROC AUC Score: 0.6545\n",
      "Confusion Matrix:\n",
      "[[17 24]\n",
      " [ 0 12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.41      0.59        41\n",
      "           1       0.33      1.00      0.50        12\n",
      "\n",
      "    accuracy                           0.55        53\n",
      "   macro avg       0.67      0.71      0.54        53\n",
      "weighted avg       0.85      0.55      0.57        53\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Optimal Threshold (Youden's J): 0.1432\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.5283\n",
      "Precision: 0.3243\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.4898\n",
      "ROC AUC Score: 0.6707\n",
      "Confusion Matrix:\n",
      "[[16 25]\n",
      " [ 0 12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56        41\n",
      "           1       0.32      1.00      0.49        12\n",
      "\n",
      "    accuracy                           0.53        53\n",
      "   macro avg       0.66      0.70      0.53        53\n",
      "weighted avg       0.85      0.53      0.55        53\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Optimal Threshold (Youden's J): 0.3384\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.4151\n",
      "Precision: 0.2791\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.4364\n",
      "ROC AUC Score: 0.6077\n",
      "Confusion Matrix:\n",
      "[[10 31]\n",
      " [ 0 12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.39        41\n",
      "           1       0.28      1.00      0.44        12\n",
      "\n",
      "    accuracy                           0.42        53\n",
      "   macro avg       0.64      0.62      0.41        53\n",
      "weighted avg       0.84      0.42      0.40        53\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Optimal Threshold (Youden's J): 0.3451\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.7170\n",
      "Precision: 0.4286\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.5455\n",
      "ROC AUC Score: 0.6890\n",
      "Confusion Matrix:\n",
      "[[29 12]\n",
      " [ 3  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.79        41\n",
      "           1       0.43      0.75      0.55        12\n",
      "\n",
      "    accuracy                           0.72        53\n",
      "   macro avg       0.67      0.73      0.67        53\n",
      "weighted avg       0.80      0.72      0.74        53\n",
      "\n",
      "\n",
      "Adjusting Thresholds for Image Dataset:\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Optimal Threshold (Youden's J): 0.0006\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.3656\n",
      "Precision: 0.2658\n",
      "Recall: 0.9294\n",
      "F1 Score: 0.4134\n",
      "ROC AUC Score: 0.4876\n",
      "Confusion Matrix:\n",
      "[[ 251 1091]\n",
      " [  30  395]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.19      0.31      1342\n",
      "           1       0.27      0.93      0.41       425\n",
      "\n",
      "    accuracy                           0.37      1767\n",
      "   macro avg       0.58      0.56      0.36      1767\n",
      "weighted avg       0.74      0.37      0.33      1767\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Optimal Threshold (Youden's J): 0.3658\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.6802\n",
      "Precision: 0.3187\n",
      "Recall: 0.2894\n",
      "F1 Score: 0.3033\n",
      "ROC AUC Score: 0.5482\n",
      "Confusion Matrix:\n",
      "[[1079  263]\n",
      " [ 302  123]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1342\n",
      "           1       0.32      0.29      0.30       425\n",
      "\n",
      "    accuracy                           0.68      1767\n",
      "   macro avg       0.55      0.55      0.55      1767\n",
      "weighted avg       0.67      0.68      0.67      1767\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Optimal Threshold (Youden's J): 0.2773\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.6038\n",
      "Precision: 0.2875\n",
      "Recall: 0.4376\n",
      "F1 Score: 0.3470\n",
      "ROC AUC Score: 0.5318\n",
      "Confusion Matrix:\n",
      "[[881 461]\n",
      " [239 186]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72      1342\n",
      "           1       0.29      0.44      0.35       425\n",
      "\n",
      "    accuracy                           0.60      1767\n",
      "   macro avg       0.54      0.55      0.53      1767\n",
      "weighted avg       0.67      0.60      0.63      1767\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Optimal Threshold (Youden's J): 0.0001\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.3396\n",
      "Precision: 0.2513\n",
      "Recall: 0.8824\n",
      "F1 Score: 0.3912\n",
      "ROC AUC Score: 0.5189\n",
      "Confusion Matrix:\n",
      "[[ 225 1117]\n",
      " [  50  375]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.17      0.28      1342\n",
      "           1       0.25      0.88      0.39       425\n",
      "\n",
      "    accuracy                           0.34      1767\n",
      "   macro avg       0.53      0.53      0.33      1767\n",
      "weighted avg       0.68      0.34      0.31      1767\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Optimal Threshold (Youden's J): 0.0028\n",
      "Adjusted Threshold Test Results:\n",
      "Accuracy: 0.3939\n",
      "Precision: 0.2686\n",
      "Recall: 0.8824\n",
      "F1 Score: 0.4119\n",
      "ROC AUC Score: 0.4999\n",
      "Confusion Matrix:\n",
      "[[ 321 1021]\n",
      " [  50  375]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.24      0.37      1342\n",
      "           1       0.27      0.88      0.41       425\n",
      "\n",
      "    accuracy                           0.39      1767\n",
      "   macro avg       0.57      0.56      0.39      1767\n",
      "weighted avg       0.72      0.39      0.38      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Updated Youden's J Threshold Adjustment Cell\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Define a consistent suffix for adjusted classifiers\n",
    "THRESHOLD_ADJUSTED_SUFFIX = ' (Threshold Adjusted)'\n",
    "\n",
    "# Helper function to extract the base classifier name by removing any suffix in parentheses\n",
    "def get_base_classifier_name(name):\n",
    "    if '(' in name and ')' in name:\n",
    "        return name.split('(')[0].strip()\n",
    "    return name\n",
    "\n",
    "# Function to find optimal threshold using Youden's J-statistic\n",
    "def find_optimal_threshold(y_true, y_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    optimal_threshold = thresholds[ix]\n",
    "    print(f\"Optimal Threshold (Youden's J): {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "# Apply threshold adjustment to each classifier on each dataset\n",
    "for dataset_name in test_results.keys():\n",
    "    print(f\"\\nAdjusting Thresholds for {dataset_name} Dataset:\")\n",
    "    classifier_names = list(test_results[dataset_name].keys())  # Get current classifier names\n",
    "    for classifier_name in classifier_names:\n",
    "        if THRESHOLD_ADJUSTED_SUFFIX in classifier_name:\n",
    "            continue  # Skip already adjusted classifiers\n",
    "        print(f\"\\nClassifier: {classifier_name}\")\n",
    "        \n",
    "        # Retrieve the pipeline and test data\n",
    "        data = data_splits[dataset_name]\n",
    "        X_test_full = data['X_test_full']\n",
    "        y_test = data['y_test']\n",
    "        X_train_full = data['X_train_full']\n",
    "        y_train_full = data['y_train_full']\n",
    "        \n",
    "        # Extract base classifier name\n",
    "        base_classifier_name = get_base_classifier_name(classifier_name)\n",
    "        \n",
    "        # Get the best hyperparameters from nested_cv_results\n",
    "        nested_results = nested_cv_results[dataset_name]\n",
    "        cv_results_all = nested_results['cv_results_all']\n",
    "        try:\n",
    "            cv_results = cv_results_all[base_classifier_name]\n",
    "        except KeyError:\n",
    "            print(f\"Error: '{base_classifier_name}' not found in cv_results_all for dataset '{dataset_name}'. Skipping threshold adjustment for this classifier.\")\n",
    "            continue\n",
    "        \n",
    "        # Find the hyperparameters with the best mean_test_score (F1 score)\n",
    "        max_mean_test_score = cv_results['mean_test_score'].max()\n",
    "        best_rows = cv_results[cv_results['mean_test_score'] == max_mean_test_score]\n",
    "        \n",
    "        # If multiple rows have the same max score, pick the first one\n",
    "        best_row = best_rows.iloc[0]\n",
    "        \n",
    "        # Extract the best hyperparameters from the pipeline parameters\n",
    "        best_params = best_row['params']\n",
    "        \n",
    "        # The params are for the entire pipeline; extract classifier's hyperparameters\n",
    "        classifier_params = {}\n",
    "        for param_name, param_value in best_params.items():\n",
    "            if param_name.startswith('classifier__'):\n",
    "                # Remove 'classifier__' prefix to get the parameter name\n",
    "                param_short = param_name.replace('classifier__', '')\n",
    "                classifier_params[param_short] = param_value\n",
    "        \n",
    "        # Get the default classifier from the classifiers dictionary\n",
    "        default_classifier = classifiers[base_classifier_name]\n",
    "        \n",
    "        # Clone the default classifier to avoid modifying the original\n",
    "        classifier = clone(default_classifier)\n",
    "        \n",
    "        # Update the classifier's parameters with the best hyperparameters\n",
    "        classifier.set_params(**classifier_params)\n",
    "        \n",
    "        # Handle compatibility between solver and penalty for Logistic Regression\n",
    "        if base_classifier_name == 'Logistic Regression':\n",
    "            penalty = classifier.get_params().get('penalty', 'l2')\n",
    "            solver = classifier.get_params().get('solver', 'lbfgs')\n",
    "            if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "                # Change solver to 'liblinear' if penalty is 'l1'\n",
    "                classifier.set_params(solver='liblinear')\n",
    "                print(f\"Adjusted solver to 'liblinear' for 'l1' penalty.\")\n",
    "            elif penalty == 'elasticnet' and solver != 'saga':\n",
    "                # 'elasticnet' penalty requires 'saga' solver\n",
    "                classifier.set_params(solver='saga')\n",
    "                print(f\"Adjusted solver to 'saga' for 'elasticnet' penalty.\")\n",
    "            elif penalty == 'l2' and solver == 'liblinear' and classifier.get_params().get('dual', False):\n",
    "                # Dual formulation is only implemented for l2 penalty with liblinear solver\n",
    "                classifier.set_params(dual=True)\n",
    "            else:\n",
    "                # Ensure dual is False for other solvers\n",
    "                classifier.set_params(dual=False)\n",
    "        \n",
    "        # Define the pipeline with SMOTE, scaling, and the classifier\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        \n",
    "        # Fit the pipeline on the entire training set\n",
    "        pipeline.fit(X_train_full, y_train_full)\n",
    "        \n",
    "        # Compute predicted probabilities\n",
    "        y_proba = pipeline.predict_proba(X_test_full)[:, 1] if hasattr(pipeline, \"predict_proba\") else None\n",
    "        \n",
    "        # Check if y_proba is available\n",
    "        if y_proba is None:\n",
    "            print(\"Predicted probabilities not available. Skipping threshold adjustment.\")\n",
    "            continue\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test, y_proba)\n",
    "        \n",
    "        # Make predictions with the optimal threshold\n",
    "        y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred_optimal)\n",
    "        precision = precision_score(y_test, y_pred_optimal, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred_optimal)\n",
    "        f1 = f1_score(y_test, y_pred_optimal)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimal)\n",
    "        class_report = classification_report(y_test, y_pred_optimal, zero_division=0)\n",
    "        \n",
    "        # Define the adjusted classifier name\n",
    "        adjusted_classifier_name = f\"{base_classifier_name}{THRESHOLD_ADJUSTED_SUFFIX}\"\n",
    "        \n",
    "        # Update the results with adjusted threshold\n",
    "        test_results[dataset_name][adjusted_classifier_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "        \n",
    "        # Print the results\n",
    "        print(f\"Adjusted Threshold Test Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"Classification Report:\")\n",
    "        print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dataset           Classifier  Best Score (F1) classifier__penalty  \\\n",
      "0   Combined  Logistic Regression         0.635256                  l2   \n",
      "1   Combined        Random Forest         0.351208                 NaN   \n",
      "2   Combined              XGBoost         0.530723                 NaN   \n",
      "3   Combined             LightGBM         0.459403                 NaN   \n",
      "4   Combined                  SVM         0.668000                 NaN   \n",
      "5   Clinical  Logistic Regression         0.483243                  l1   \n",
      "6   Clinical        Random Forest         0.345238                 NaN   \n",
      "7   Clinical              XGBoost         0.378655                 NaN   \n",
      "8   Clinical             LightGBM         0.514583                 NaN   \n",
      "9   Clinical                  SVM         0.524493                 NaN   \n",
      "10     Image  Logistic Regression         0.631439                  l2   \n",
      "11     Image        Random Forest         0.303997                 NaN   \n",
      "12     Image              XGBoost         0.390344                 NaN   \n",
      "13     Image             LightGBM         0.332852                 NaN   \n",
      "14     Image                  SVM         0.632115                 NaN   \n",
      "\n",
      "    classifier__C  classifier__n_estimators  classifier__min_samples_split  \\\n",
      "0      166.810054                       NaN                            NaN   \n",
      "1             NaN                      50.0                            2.0   \n",
      "2             NaN                     100.0                            NaN   \n",
      "3             NaN                     200.0                            NaN   \n",
      "4        0.100000                       NaN                            NaN   \n",
      "5        0.359381                       NaN                            NaN   \n",
      "6             NaN                      50.0                            2.0   \n",
      "7             NaN                     200.0                            NaN   \n",
      "8             NaN                      50.0                            NaN   \n",
      "9        0.100000                       NaN                            NaN   \n",
      "10     166.810054                       NaN                            NaN   \n",
      "11            NaN                     200.0                            2.0   \n",
      "12            NaN                     100.0                            NaN   \n",
      "13            NaN                     200.0                            NaN   \n",
      "14       0.100000                       NaN                            NaN   \n",
      "\n",
      "    classifier__min_samples_leaf  classifier__max_depth  \\\n",
      "0                            NaN                    NaN   \n",
      "1                            2.0                   10.0   \n",
      "2                            NaN                    3.0   \n",
      "3                            NaN                    NaN   \n",
      "4                            NaN                    NaN   \n",
      "5                            NaN                    NaN   \n",
      "6                            2.0                   20.0   \n",
      "7                            NaN                   10.0   \n",
      "8                            NaN                    NaN   \n",
      "9                            NaN                    NaN   \n",
      "10                           NaN                    NaN   \n",
      "11                           2.0                   10.0   \n",
      "12                           NaN                    3.0   \n",
      "13                           NaN                    NaN   \n",
      "14                           NaN                    NaN   \n",
      "\n",
      "    classifier__learning_rate  classifier__verbose  classifier__num_leaves  \\\n",
      "0                         NaN                  NaN                     NaN   \n",
      "1                         NaN                  NaN                     NaN   \n",
      "2                        0.10                  NaN                     NaN   \n",
      "3                        0.10                 -1.0                    31.0   \n",
      "4                         NaN                  NaN                     NaN   \n",
      "5                         NaN                  NaN                     NaN   \n",
      "6                         NaN                  NaN                     NaN   \n",
      "7                        0.01                  NaN                     NaN   \n",
      "8                        0.01                 -1.0                    31.0   \n",
      "9                         NaN                  NaN                     NaN   \n",
      "10                        NaN                  NaN                     NaN   \n",
      "11                        NaN                  NaN                     NaN   \n",
      "12                       0.10                  NaN                     NaN   \n",
      "13                       0.10                 -1.0                    31.0   \n",
      "14                        NaN                  NaN                     NaN   \n",
      "\n",
      "   classifier__kernel  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4              linear  \n",
      "5                 NaN  \n",
      "6                 NaN  \n",
      "7                 NaN  \n",
      "8                 NaN  \n",
      "9              linear  \n",
      "10                NaN  \n",
      "11                NaN  \n",
      "12                NaN  \n",
      "13                NaN  \n",
      "14             linear  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the best parameters\n",
    "best_parameters = []\n",
    "\n",
    "# Iterate through each dataset in nested_cv_results\n",
    "for dataset, dataset_results in nested_cv_results.items():\n",
    "    cv_results_all = dataset_results.get('cv_results_all', {})\n",
    "    \n",
    "    # Iterate through each classifier in the current dataset\n",
    "    for classifier, cv_results in cv_results_all.items():\n",
    "        if cv_results.empty:\n",
    "            print(f\"No cross-validation results found for {classifier} in {dataset}.\")\n",
    "            continue\n",
    "        \n",
    "        # Identify the row with the highest mean_test_score\n",
    "        best_row = cv_results.loc[cv_results['mean_test_score'].idxmax()]\n",
    "        best_params = best_row['params']\n",
    "        best_score = best_row['mean_test_score']\n",
    "        \n",
    "        # Append the results to the list\n",
    "        best_parameters.append({\n",
    "            'Dataset': dataset,\n",
    "            'Classifier': classifier,\n",
    "            'Best Score (F1)': best_score,\n",
    "            'Best Hyperparameters': best_params\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "best_params_df = pd.DataFrame(best_parameters)\n",
    "\n",
    "# Optional: Expand the 'Best Hyperparameters' column for better readability\n",
    "# This will create separate columns for each hyperparameter\n",
    "best_params_expanded = best_params_df.join(\n",
    "    best_params_df.pop('Best Hyperparameters').apply(pd.Series)\n",
    ")\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "pd.set_option('display.max_colwidth', None)  # Ensure full visibility of hyperparameters\n",
    "print(best_params_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusting Thresholds for Combined Dataset (Precision-Recall):\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Optimal Threshold (Best F1): 0.2293\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.6995\n",
      "Precision: 0.4227\n",
      "Recall: 0.6824\n",
      "F1 Score: 0.5221\n",
      "ROC AUC Score: 0.7097\n",
      "Confusion Matrix:\n",
      "[[946 396]\n",
      " [135 290]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78      1342\n",
      "           1       0.42      0.68      0.52       425\n",
      "\n",
      "    accuracy                           0.70      1767\n",
      "   macro avg       0.65      0.69      0.65      1767\n",
      "weighted avg       0.77      0.70      0.72      1767\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Optimal Threshold (Best F1): 0.2100\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.6984\n",
      "Precision: 0.4260\n",
      "Recall: 0.7318\n",
      "F1 Score: 0.5385\n",
      "ROC AUC Score: 0.7193\n",
      "Confusion Matrix:\n",
      "[[923 419]\n",
      " [114 311]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.78      1342\n",
      "           1       0.43      0.73      0.54       425\n",
      "\n",
      "    accuracy                           0.70      1767\n",
      "   macro avg       0.66      0.71      0.66      1767\n",
      "weighted avg       0.78      0.70      0.72      1767\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Optimal Threshold (Best F1): 0.0066\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.6740\n",
      "Precision: 0.3981\n",
      "Recall: 0.6941\n",
      "F1 Score: 0.5060\n",
      "ROC AUC Score: 0.6974\n",
      "Confusion Matrix:\n",
      "[[896 446]\n",
      " [130 295]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      1342\n",
      "           1       0.40      0.69      0.51       425\n",
      "\n",
      "    accuracy                           0.67      1767\n",
      "   macro avg       0.64      0.68      0.63      1767\n",
      "weighted avg       0.76      0.67      0.70      1767\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Optimal Threshold (Best F1): 0.0162\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.6655\n",
      "Precision: 0.3973\n",
      "Recall: 0.7553\n",
      "F1 Score: 0.5207\n",
      "ROC AUC Score: 0.7018\n",
      "Confusion Matrix:\n",
      "[[855 487]\n",
      " [104 321]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.64      0.74      1342\n",
      "           1       0.40      0.76      0.52       425\n",
      "\n",
      "    accuracy                           0.67      1767\n",
      "   macro avg       0.64      0.70      0.63      1767\n",
      "weighted avg       0.77      0.67      0.69      1767\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Optimal Threshold (Best F1): 0.0031\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.7182\n",
      "Precision: 0.4391\n",
      "Recall: 0.6188\n",
      "F1 Score: 0.5137\n",
      "ROC AUC Score: 0.7199\n",
      "Confusion Matrix:\n",
      "[[1006  336]\n",
      " [ 162  263]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      1342\n",
      "           1       0.44      0.62      0.51       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.65      0.68      0.66      1767\n",
      "weighted avg       0.76      0.72      0.73      1767\n",
      "\n",
      "\n",
      "Adjusting Thresholds for Clinical Dataset (Precision-Recall):\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Optimal Threshold (Best F1): 0.4107\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.7736\n",
      "Precision: 0.5000\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.6000\n",
      "ROC AUC Score: 0.7378\n",
      "Confusion Matrix:\n",
      "[[32  9]\n",
      " [ 3  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84        41\n",
      "           1       0.50      0.75      0.60        12\n",
      "\n",
      "    accuracy                           0.77        53\n",
      "   macro avg       0.71      0.77      0.72        53\n",
      "weighted avg       0.82      0.77      0.79        53\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Optimal Threshold (Best F1): 0.2000\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.5283\n",
      "Precision: 0.3030\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.4444\n",
      "ROC AUC Score: 0.6514\n",
      "Confusion Matrix:\n",
      "[[18 23]\n",
      " [ 2 10]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.44      0.59        41\n",
      "           1       0.30      0.83      0.44        12\n",
      "\n",
      "    accuracy                           0.53        53\n",
      "   macro avg       0.60      0.64      0.52        53\n",
      "weighted avg       0.76      0.53      0.56        53\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Optimal Threshold (Best F1): 0.1671\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.7547\n",
      "Precision: 0.4615\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.4800\n",
      "ROC AUC Score: 0.6362\n",
      "Confusion Matrix:\n",
      "[[34  7]\n",
      " [ 6  6]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84        41\n",
      "           1       0.46      0.50      0.48        12\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.66      0.66      0.66        53\n",
      "weighted avg       0.76      0.75      0.76        53\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Optimal Threshold (Best F1): 0.0521\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.5660\n",
      "Precision: 0.3103\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.4390\n",
      "ROC AUC Score: 0.6240\n",
      "Confusion Matrix:\n",
      "[[21 20]\n",
      " [ 3  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.51      0.65        41\n",
      "           1       0.31      0.75      0.44        12\n",
      "\n",
      "    accuracy                           0.57        53\n",
      "   macro avg       0.59      0.63      0.54        53\n",
      "weighted avg       0.75      0.57      0.60        53\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Optimal Threshold (Best F1): 0.2863\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.7547\n",
      "Precision: 0.4667\n",
      "Recall: 0.5833\n",
      "F1 Score: 0.5185\n",
      "ROC AUC Score: 0.6911\n",
      "Confusion Matrix:\n",
      "[[33  8]\n",
      " [ 5  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84        41\n",
      "           1       0.47      0.58      0.52        12\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.67      0.69      0.68        53\n",
      "weighted avg       0.78      0.75      0.76        53\n",
      "\n",
      "\n",
      "Adjusting Thresholds for Image Dataset (Precision-Recall):\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Optimal Threshold (Best F1): 0.0075\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.3939\n",
      "Precision: 0.2703\n",
      "Recall: 0.8941\n",
      "F1 Score: 0.4151\n",
      "ROC AUC Score: 0.4988\n",
      "Confusion Matrix:\n",
      "[[ 316 1026]\n",
      " [  45  380]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.24      0.37      1342\n",
      "           1       0.27      0.89      0.42       425\n",
      "\n",
      "    accuracy                           0.39      1767\n",
      "   macro avg       0.57      0.56      0.39      1767\n",
      "weighted avg       0.73      0.39      0.38      1767\n",
      "\n",
      "\n",
      "Classifier: Random Forest\n",
      "Optimal Threshold (Best F1): 0.0000\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.2405\n",
      "Precision: 0.2405\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.3878\n",
      "ROC AUC Score: 0.5480\n",
      "Confusion Matrix:\n",
      "[[   0 1342]\n",
      " [   0  425]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1342\n",
      "           1       0.24      1.00      0.39       425\n",
      "\n",
      "    accuracy                           0.24      1767\n",
      "   macro avg       0.12      0.50      0.19      1767\n",
      "weighted avg       0.06      0.24      0.09      1767\n",
      "\n",
      "\n",
      "Classifier: XGBoost\n",
      "Optimal Threshold (Best F1): 0.0000\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.2592\n",
      "Precision: 0.2442\n",
      "Recall: 0.9929\n",
      "F1 Score: 0.3920\n",
      "ROC AUC Score: 0.5286\n",
      "Confusion Matrix:\n",
      "[[  36 1306]\n",
      " [   3  422]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.03      0.05      1342\n",
      "           1       0.24      0.99      0.39       425\n",
      "\n",
      "    accuracy                           0.26      1767\n",
      "   macro avg       0.58      0.51      0.22      1767\n",
      "weighted avg       0.76      0.26      0.13      1767\n",
      "\n",
      "\n",
      "Classifier: LightGBM\n",
      "Optimal Threshold (Best F1): 0.0023\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.3169\n",
      "Precision: 0.2525\n",
      "Recall: 0.9388\n",
      "F1 Score: 0.3980\n",
      "ROC AUC Score: 0.5319\n",
      "Confusion Matrix:\n",
      "[[ 161 1181]\n",
      " [  26  399]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.12      0.21      1342\n",
      "           1       0.25      0.94      0.40       425\n",
      "\n",
      "    accuracy                           0.32      1767\n",
      "   macro avg       0.56      0.53      0.30      1767\n",
      "weighted avg       0.71      0.32      0.26      1767\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "Optimal Threshold (Best F1): 0.0000\n",
      "Adjusted Threshold Test Results (Best F1):\n",
      "Accuracy: 0.3486\n",
      "Precision: 0.2510\n",
      "Recall: 0.8612\n",
      "F1 Score: 0.3887\n",
      "ROC AUC Score: 0.4988\n",
      "Confusion Matrix:\n",
      "[[ 250 1092]\n",
      " [  59  366]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.19      0.30      1342\n",
      "           1       0.25      0.86      0.39       425\n",
      "\n",
      "    accuracy                           0.35      1767\n",
      "   macro avg       0.53      0.52      0.35      1767\n",
      "weighted avg       0.67      0.35      0.32      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementing Precision-Recall Curve Based Threshold Adjustment\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Function to find optimal threshold maximizing F1 score\n",
    "def find_best_f1_threshold(y_true, y_proba):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    ix = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[ix]\n",
    "    print(f\"Optimal Threshold (Best F1): {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "# Apply threshold adjustment to each classifier on each dataset\n",
    "for dataset_name in test_results.keys():\n",
    "    print(f\"\\nAdjusting Thresholds for {dataset_name} Dataset (Precision-Recall):\")\n",
    "    classifier_names = list(test_results[dataset_name].keys())\n",
    "    for classifier_name in classifier_names:\n",
    "        if '(Best F1 Threshold)' in classifier_name or '(Threshold Adjusted)' in classifier_name:\n",
    "            continue  # Skip already adjusted classifiers\n",
    "        print(f\"\\nClassifier: {classifier_name}\")\n",
    "        # Retrieve the pipeline and test data\n",
    "        data = data_splits[dataset_name]\n",
    "        X_test_full = data['X_test_full']\n",
    "        y_test = data['y_test']\n",
    "        X_train_full = data['X_train_full']\n",
    "        y_train_full = data['y_train_full']\n",
    "        \n",
    "        # Get the base classifier name\n",
    "        base_classifier_name = classifier_name.split(' (')[0]\n",
    "        \n",
    "        # Re-fit the model if necessary\n",
    "        try:\n",
    "            classifier = clone(classifiers[base_classifier_name])\n",
    "        except KeyError:\n",
    "            print(f\"Classifier '{base_classifier_name}' not found in classifiers dictionary.\")\n",
    "            continue  # Skip to the next classifier\n",
    "        \n",
    "        # Ensure probability estimates are available\n",
    "        if hasattr(classifier, 'probability') and not classifier.probability:\n",
    "            classifier.probability = True  # Enable probability estimates for SVM\n",
    "        \n",
    "        # Define the pipeline\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        \n",
    "        # Fit the pipeline on the entire training set\n",
    "        pipeline.fit(X_train_full, y_train_full)\n",
    "        \n",
    "        # Compute predicted probabilities\n",
    "        if hasattr(pipeline.named_steps['classifier'], \"predict_proba\"):\n",
    "            y_proba = pipeline.predict_proba(X_test_full)[:, 1]\n",
    "        else:\n",
    "            print(f\"Classifier '{classifier_name}' does not support probability estimates.\")\n",
    "            continue  # Skip to the next classifier\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_best_f1_threshold(y_test, y_proba)\n",
    "        \n",
    "        # Make predictions with the optimal threshold\n",
    "        y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred_optimal)\n",
    "        precision = precision_score(y_test, y_pred_optimal, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred_optimal)\n",
    "        f1 = f1_score(y_test, y_pred_optimal)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_optimal)\n",
    "        class_report = classification_report(y_test, y_pred_optimal, zero_division=0)\n",
    "        \n",
    "        # Update the results\n",
    "        test_results[dataset_name][classifier_name + ' (Best F1 Threshold)'] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "        \n",
    "        print(f\"Adjusted Threshold Test Results (Best F1):\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"Classification Report:\")\n",
    "        print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retraining and Evaluating Calibrated Models for Combined Dataset\n",
      "\n",
      "Retraining Logistic Regression with Calibration on Combined dataset...\n",
      "Logistic Regression Calibrated Test Results on Combined Dataset:\n",
      "Accuracy: 0.7521\n",
      "Precision: 0.4853\n",
      "Recall: 0.5035\n",
      "F1 Score: 0.4942\n",
      "ROC AUC Score: 0.7112\n",
      "Confusion Matrix:\n",
      "[[1115  227]\n",
      " [ 211  214]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1342\n",
      "           1       0.49      0.50      0.49       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.66      0.67      0.67      1767\n",
      "weighted avg       0.76      0.75      0.75      1767\n",
      "\n",
      "\n",
      "Retraining Random Forest with Calibration on Combined dataset...\n",
      "Random Forest Calibrated Test Results on Combined Dataset:\n",
      "Accuracy: 0.7555\n",
      "Precision: 0.4255\n",
      "Recall: 0.0471\n",
      "F1 Score: 0.0847\n",
      "ROC AUC Score: 0.7276\n",
      "Confusion Matrix:\n",
      "[[1315   27]\n",
      " [ 405   20]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86      1342\n",
      "           1       0.43      0.05      0.08       425\n",
      "\n",
      "    accuracy                           0.76      1767\n",
      "   macro avg       0.60      0.51      0.47      1767\n",
      "weighted avg       0.68      0.76      0.67      1767\n",
      "\n",
      "\n",
      "Retraining XGBoost with Calibration on Combined dataset...\n",
      "XGBoost Calibrated Test Results on Combined Dataset:\n",
      "Accuracy: 0.7544\n",
      "Precision: 0.4634\n",
      "Recall: 0.1341\n",
      "F1 Score: 0.2080\n",
      "ROC AUC Score: 0.7228\n",
      "Confusion Matrix:\n",
      "[[1276   66]\n",
      " [ 368   57]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85      1342\n",
      "           1       0.46      0.13      0.21       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.62      0.54      0.53      1767\n",
      "weighted avg       0.70      0.75      0.70      1767\n",
      "\n",
      "\n",
      "Retraining LightGBM with Calibration on Combined dataset...\n",
      "LightGBM Calibrated Test Results on Combined Dataset:\n",
      "Accuracy: 0.7521\n",
      "Precision: 0.4511\n",
      "Recall: 0.1412\n",
      "F1 Score: 0.2151\n",
      "ROC AUC Score: 0.7259\n",
      "Confusion Matrix:\n",
      "[[1269   73]\n",
      " [ 365   60]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85      1342\n",
      "           1       0.45      0.14      0.22       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.61      0.54      0.53      1767\n",
      "weighted avg       0.70      0.75      0.70      1767\n",
      "\n",
      "\n",
      "Retraining SVM with Calibration on Combined dataset...\n",
      "SVM Calibrated Test Results on Combined Dataset:\n",
      "Accuracy: 0.7589\n",
      "Precision: 0.4980\n",
      "Recall: 0.2965\n",
      "F1 Score: 0.3717\n",
      "ROC AUC Score: 0.7207\n",
      "Confusion Matrix:\n",
      "[[1215  127]\n",
      " [ 299  126]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85      1342\n",
      "           1       0.50      0.30      0.37       425\n",
      "\n",
      "    accuracy                           0.76      1767\n",
      "   macro avg       0.65      0.60      0.61      1767\n",
      "weighted avg       0.73      0.76      0.74      1767\n",
      "\n",
      "\n",
      "Retraining and Evaluating Calibrated Models for Clinical Dataset\n",
      "\n",
      "Retraining Logistic Regression with Calibration on Clinical dataset...\n",
      "Logistic Regression Calibrated Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7736\n",
      "Precision: 0.5000\n",
      "Recall: 0.5833\n",
      "F1 Score: 0.5385\n",
      "ROC AUC Score: 0.7378\n",
      "Confusion Matrix:\n",
      "[[34  7]\n",
      " [ 5  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85        41\n",
      "           1       0.50      0.58      0.54        12\n",
      "\n",
      "    accuracy                           0.77        53\n",
      "   macro avg       0.69      0.71      0.69        53\n",
      "weighted avg       0.79      0.77      0.78        53\n",
      "\n",
      "\n",
      "Retraining Random Forest with Calibration on Clinical dataset...\n",
      "Random Forest Calibrated Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7736\n",
      "Precision: 0.5000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.4000\n",
      "ROC AUC Score: 0.6463\n",
      "Confusion Matrix:\n",
      "[[37  4]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        41\n",
      "           1       0.50      0.33      0.40        12\n",
      "\n",
      "    accuracy                           0.77        53\n",
      "   macro avg       0.66      0.62      0.63        53\n",
      "weighted avg       0.75      0.77      0.76        53\n",
      "\n",
      "\n",
      "Retraining XGBoost with Calibration on Clinical dataset...\n",
      "XGBoost Calibrated Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7358\n",
      "Precision: 0.4000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3636\n",
      "ROC AUC Score: 0.6829\n",
      "Confusion Matrix:\n",
      "[[35  6]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        41\n",
      "           1       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.61      0.59      0.60        53\n",
      "weighted avg       0.72      0.74      0.73        53\n",
      "\n",
      "\n",
      "Retraining LightGBM with Calibration on Clinical dataset...\n",
      "LightGBM Calibrated Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7358\n",
      "Precision: 0.4000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3636\n",
      "ROC AUC Score: 0.6199\n",
      "Confusion Matrix:\n",
      "[[35  6]\n",
      " [ 8  4]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        41\n",
      "           1       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.61      0.59      0.60        53\n",
      "weighted avg       0.72      0.74      0.73        53\n",
      "\n",
      "\n",
      "Retraining SVM with Calibration on Clinical dataset...\n",
      "SVM Calibrated Test Results on Clinical Dataset:\n",
      "Accuracy: 0.7358\n",
      "Precision: 0.3333\n",
      "Recall: 0.1667\n",
      "F1 Score: 0.2222\n",
      "ROC AUC Score: 0.7033\n",
      "Confusion Matrix:\n",
      "[[37  4]\n",
      " [10  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        41\n",
      "           1       0.33      0.17      0.22        12\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.56      0.53      0.53        53\n",
      "weighted avg       0.68      0.74      0.70        53\n",
      "\n",
      "\n",
      "Retraining and Evaluating Calibrated Models for Image Dataset\n",
      "\n",
      "Retraining Logistic Regression with Calibration on Image dataset...\n",
      "Logistic Regression Calibrated Test Results on Image Dataset:\n",
      "Accuracy: 0.6157\n",
      "Precision: 0.1976\n",
      "Recall: 0.1953\n",
      "F1 Score: 0.1964\n",
      "ROC AUC Score: 0.5004\n",
      "Confusion Matrix:\n",
      "[[1005  337]\n",
      " [ 342   83]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1342\n",
      "           1       0.20      0.20      0.20       425\n",
      "\n",
      "    accuracy                           0.62      1767\n",
      "   macro avg       0.47      0.47      0.47      1767\n",
      "weighted avg       0.61      0.62      0.61      1767\n",
      "\n",
      "\n",
      "Retraining Random Forest with Calibration on Image dataset...\n",
      "Random Forest Calibrated Test Results on Image Dataset:\n",
      "Accuracy: 0.7504\n",
      "Precision: 0.3788\n",
      "Recall: 0.0588\n",
      "F1 Score: 0.1018\n",
      "ROC AUC Score: 0.5186\n",
      "Confusion Matrix:\n",
      "[[1301   41]\n",
      " [ 400   25]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.86      1342\n",
      "           1       0.38      0.06      0.10       425\n",
      "\n",
      "    accuracy                           0.75      1767\n",
      "   macro avg       0.57      0.51      0.48      1767\n",
      "weighted avg       0.67      0.75      0.67      1767\n",
      "\n",
      "\n",
      "Retraining XGBoost with Calibration on Image dataset...\n",
      "XGBoost Calibrated Test Results on Image Dataset:\n",
      "Accuracy: 0.7165\n",
      "Precision: 0.2738\n",
      "Recall: 0.1082\n",
      "F1 Score: 0.1551\n",
      "ROC AUC Score: 0.5029\n",
      "Confusion Matrix:\n",
      "[[1220  122]\n",
      " [ 379   46]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      1342\n",
      "           1       0.27      0.11      0.16       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.52      0.51      0.49      1767\n",
      "weighted avg       0.65      0.72      0.67      1767\n",
      "\n",
      "\n",
      "Retraining LightGBM with Calibration on Image dataset...\n",
      "LightGBM Calibrated Test Results on Image Dataset:\n",
      "Accuracy: 0.7250\n",
      "Precision: 0.3007\n",
      "Recall: 0.1082\n",
      "F1 Score: 0.1592\n",
      "ROC AUC Score: 0.5160\n",
      "Confusion Matrix:\n",
      "[[1235  107]\n",
      " [ 379   46]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1342\n",
      "           1       0.30      0.11      0.16       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.53      0.51      0.50      1767\n",
      "weighted avg       0.65      0.72      0.67      1767\n",
      "\n",
      "\n",
      "Retraining SVM with Calibration on Image dataset...\n",
      "SVM Calibrated Test Results on Image Dataset:\n",
      "Accuracy: 0.7182\n",
      "Precision: 0.2788\n",
      "Recall: 0.1082\n",
      "F1 Score: 0.1559\n",
      "ROC AUC Score: 0.5043\n",
      "Confusion Matrix:\n",
      "[[1223  119]\n",
      " [ 379   46]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83      1342\n",
      "           1       0.28      0.11      0.16       425\n",
      "\n",
      "    accuracy                           0.72      1767\n",
      "   macro avg       0.52      0.51      0.49      1767\n",
      "weighted avg       0.65      0.72      0.67      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementing Calibrated Classifiers\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Retrain Models with Calibrated Classifiers and Evaluate on Test Set\n",
    "\n",
    "calibrated_test_results = {}  # To store test set results for calibrated classifiers\n",
    "\n",
    "for dataset_name in data_splits.keys():\n",
    "    print(f\"\\nRetraining and Evaluating Calibrated Models for {dataset_name} Dataset\")\n",
    "    \n",
    "    # Retrieve data\n",
    "    data = data_splits[dataset_name]\n",
    "    X_train_full = data['X_train_full']\n",
    "    y_train_full = data['y_train_full']\n",
    "    X_test_full = data['X_test_full']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Ensure indices are reset\n",
    "    X_train_full = X_train_full.reset_index(drop=True)\n",
    "    y_train_full = y_train_full.reset_index(drop=True)\n",
    "    X_test_full = X_test_full.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    calibrated_test_results[dataset_name] = {}\n",
    "    \n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        print(f\"\\nRetraining {classifier_name} with Calibration on {dataset_name} dataset...\")\n",
    "        \n",
    "        # Clone the classifier\n",
    "        base_classifier = clone(classifier)\n",
    "        \n",
    "        # Ensure probability estimates are available if required\n",
    "        if isinstance(base_classifier, SVC) and not base_classifier.probability:\n",
    "            base_classifier.probability = True  # Enable probability estimates for SVM\n",
    "        \n",
    "        # Wrap the classifier with CalibratedClassifierCV\n",
    "        calibrated_clf = CalibratedClassifierCV(estimator=base_classifier, cv=5, method='sigmoid')\n",
    "        \n",
    "        # Define the pipeline\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('smote', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('classifier', calibrated_clf)\n",
    "        ])\n",
    "        \n",
    "        # Fit the pipeline on the entire training set\n",
    "        pipeline.fit(X_train_full, y_train_full)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        y_pred = pipeline.predict(X_test_full)\n",
    "        y_proba = pipeline.predict_proba(X_test_full)[:, 1]\n",
    "        \n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "        \n",
    "        # Store results\n",
    "        calibrated_test_results[dataset_name][classifier_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "        \n",
    "        print(f\"{classifier_name} Calibrated Test Results on {dataset_name} Dataset:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"Classification Report:\")\n",
    "        print(class_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
